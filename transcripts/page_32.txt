Kronikle AI - Dr. Lex Fridman: Machines, Creativity & Love | Huberman Lab Podcast #29 - TranscriptDr. Lex Fridman: Machines, Creativity & Love | Huberman Lab Podcast #29 - TranscriptTranscript[0:00:00] Andrew Huberman: Welcome to the Huberman Lab Podcast, where we discuss science and science based tools for everyday life. I'm Andrew Huberman, and I'm a professor of neurobiology and ophthalmology at Stanford School of Medicine. Today, I have the pleasure of introducing doctor Lex Friedman as our guest On the Huberman Lab Podcast. Doctor Friedman is a researcher at MIT specializing in machine learning, artificial intelligence, and human robot interactions. I must say that the conversation with Lex was, without question, one of the most fascinating conversations that I've ever had, Not just in my career, but in my lifetime.[0:00:39] Andrew Huberman: I knew that Lex worked on these topics, and I think many of you are probably familiar with Lex and his interest in these topics from his incredible podcast, the Lex Fridman podcast. If you're not already watching that podcast, please subscribe to it. It is absolutely fantastic. But in holding this conversation with Lex, I realized something far more important. He revealed to us a bit of his dream, his dream about humans and robots, About humans and machines and about how those interactions can change the way that we perceive ourselves and that we interact with the world.[0:01:10] Andrew Huberman: We discuss relationships of all kinds, relationships with animals, relationships with friends, relationships with family, and romantic relationships. And we discuss relationships with machines, machines that move and machines that don't move, and machines that come to understand us in ways that we could never understand for ourselves and how those machines can educate us about ourselves. Before this conversation, I had no concept of the ways in which machines could inform me or anyone about themselves. By the end, I was absolutely taken with the idea, I'm still taken with the idea, the interactions with machines of a very particular kind, a kind that Lex understands and wants to bring to the world, Cannot only transform the self, but may very well transform humanity. So whether or not you're familiar with doctor Lex Friedman or not, certain you're going to learn a tremendous amount from him during the course of our discussion and that it will transform the way you think about yourself and about the world.[0:02:12] Andrew Huberman: Before we begin, I want to mention that this podcast is separate from my teaching and research roles at Stanford. It is, however, part of my desire and effort to bring zero cost to consumer information about science and science related tools to the general public. In keeping with that theme, I'd like to thank the sponsors of today's podcast. Our 1st sponsor is ROKA. ROKA makes sunglasses and eyeglasses that are of absolutely phenomenal quality.[0:02:35] Andrew Huberman: The company was founded by 2 all American swimmers from Stanford, And everything about the sunglasses and eyeglasses they've designed had performance in mind. Now I've spent a career working on the visual system, And one of the fundamental issues that your visual system has to deal with is how to adjust what you see when it gets darker or brighter in your environment. With ROKA sunglasses and eyeglasses, whether or not it's dim in the room or outside, whether or not there's cloud cover, whether or not you walk into a shadow, you can always see the world with absolute clarity. That just tells me that they really understand the way that the visual system works, processes like habituation and attenuation. All these things that work at a real mechanistic level have been built into these glasses.[0:03:14] Andrew Huberman: In addition, the glasses are very lightweight. You don't even notice really that they're on your face, and the quality of the lenses is terrific. Now the glasses were also designed so that you could use them not just while working or at dinner, etcetera, but while exercising. They don't fall off your face or slip off your face if you're sweating. And as I mentioned, they're extremely lightweight, so you can use them while running.[0:03:34] Andrew Huberman: You can use them while cycling and so forth. Also, the aesthetic of Roca Glasses is terrific. Unlike a lot of performance glasses out there, which frankly make people look like cyborgs, these glasses look great. You can wear them out to dinner. You can wear them in for essentially any occasion.[0:03:50] Andrew Huberman: If you'd like to try ROKA glasses, you can go to roka.com. That's roka.com And enter the code Huberman to save 20% off your first order. That's roka, roka.com, and enter the code Huberman at checkout. Today's episode is also brought to us by InsideTracker. InsideTracker is a personalized nutrition platform that analyzes data from your blood and DNA help you better understand your body and help you reach your health goals.[0:04:15] Andrew Huberman: I am a big believer in getting regular blood work done for the simple reason That many of the factors that impact our immediate and long term health can only be assessed from a quality blood test. And now with the advent of quality DNA tests, can also get insight into some of our genetic underpinnings of our current and long term health. The problem with a lot of blood and DNA tests out there, however, is you get the data back and you don't know what to do with those data. You see that certain things are high or certain things are low, but you really don't know what the actionable items are, what to do with all that information. With InsideTracker, they make it very easy to act in the appropriate ways on the information that you get back from those blood and DNA tests, and that's through the use of their Online platform.[0:04:57] Andrew Huberman: They have a really easy to use dashboard that tells you what sorts of things can bring the numbers for your metabolic factors, endocrine factors, etcetera, into the ranges that you want and need for immediate and long term health. In fact, I know 1 individual just by way of example that was feeling good, but Decided to go with an inside tracker test and discovered that they had high levels of what's called c reactive protein. They would have never detected that otherwise. C reactive protein is associated with a number of deleterious health conditions, some heart issues, eye issues, etcetera, and so they were able to take immediate action to try and Resolve those CRP levels. And so with InsideTracker, you get that sort of insight.[0:05:35] Andrew Huberman: And as I mentioned before, without a blood or DNA test, there's no way you're going to get that sort of Insight until symptoms start to show up. If you'd like to try InsideTracker, you can go to insidetracker.com/huberman To get 25% off any of InsideTracker's plans, you just use the code huberman at checkout. That's insidetracker.com slash huberman to get 25% off any of InsideTracker's plans. Today's podcast is brought to us by Athletic Greens. Athletic Greens is an all in one vitamin mineral probiotic drink.[0:06:05] Andrew Huberman: I started taking Athletic Greens way back in 2012, so I'm delighted that they're sponsoring the podcast. The reason I started taking Athletic Greens and the reason I still take Athletic Greens is that it covers all of my vitamin mineral Probiotic basis. In fact, when people ask me, what should I take? I always suggest that the 1st supplement people take is Athletic Greens. For the simple reason is that the things it contains covers your basis for metabolic health, endocrine health, and all sorts of other systems in the body.[0:06:33] Andrew Huberman: And the inclusion of probiotics are essential for a healthy gut microbiome. There are now tons of data showing that we have neurons in our gut, And keeping those neurons healthy requires that they are exposed to what are called the correct microbiota, little microorganisms that live in our gut and keep us healthy. And those neurons in turn Help keep our brain healthy. They influence things like mood, our ability to focus, and many, many other factors related to health. With Athletic Greens, it's terrific because it also tastes really good.[0:07:03] Andrew Huberman: I drink it once or twice a day. I mix mine with water, and I add a little lemon juice or sometimes a little bit of lime juice. If you wanna try Athletic Greens, you can go to athletic greens.com/huberman. And if you do that, you can claim their special offer. They're giving away 5 free travel packs, a little pack that make it easy to mix up Athletic Greens while you're on the road, and they'll give you a year supply of vitamin d 3 and k two.[0:07:26] Andrew Huberman: Again, go to athletic greens.com/huberman to claim that special offer. And now my conversation with doctor Lex Fridman. We meet again. We meet again. Thanks so much for sitting down with me.[0:07:39] Andrew Huberman: I have a question that I think is on a lot of people's minds or ought to be on a lot of people's minds because we hear these terms a lot these days, but I think most people including most scientists And including me, don't know really what is artificial intelligence and how is it different from things like machine learning and robotics. So if you would be so kind as to explain to us what is artificial intelligence And what is machine learning?[0:08:14] Dr. Lex Fridman: Well, I think that question is as complicated and as fascinating as the question of what is intelligence. So I think of artificial intelligence first as a big philosophical thing. Pamela McCordick said, AI was AI was the ancient wish to forge the gods or was born as an ancient wish to forge the gods. So I think at the big philosophical level, it's our longing to create Other intelligence systems, perhaps systems more powerful than us. At the more narrow level, I think it's also a set of Tools that are computational mathematical tools to automate different tasks.[0:09:01] Dr. Lex Fridman: And then, also, it's our attempt to understand our own mind. So build systems that exhibit some intelligent behavior in order to understand what is intelligence in our own selves. So all those things are true. Of course, what AI really means is a community, has a set of researchers and engineers. It's a set of tools, a set of, computational techniques that allow you to solve various problems.[0:09:28] Dr. Lex Fridman: The there's a long history that, approaches the problem from different perspectives. What's, always been Throughout one of the threads, one of the communities goes under the flag of machine learning, which is emphasizing In the AI space, the the task of learning. How do you make a machine that knows very little in the beginning, Follow some kind of process and learns to become better and better in a particular task. What's been most, very effective in the recent about 15 years is a set of techniques that fall under the flag of deep learning that utilize neural networks. When neural networks are are these fascinating things inspired by the structure of the human brain, very loosely, but they have, it's a network of these little basic computational units called neurons, Artificial neurons, and they have, these architectures have an input and an output.[0:10:28] Dr. Lex Fridman: They know nothing in the beginning, and they're tasked with learning something Interesting. What that something interesting is usually involves a particular task. The There's a lot of ways to talk about this and break this down. Like, one of them is how much human supervision is required to teach this thing. So supervised learning, this broad category, is, the the neural network knows nothing in the beginning, then it's given a bunch of examples of, in computer vision.[0:11:00] Dr. Lex Fridman: That will be examples of cats, dogs, cars, traffic signs. And then you're given the image and you're given the ground truth of what's in that image. And when you get a large database of such image examples where you know the where you know the truth, the, the neural network is able to learn by example. That's called supervised learning. The quest there's a lot of fascinating questions within that, which is how do you provide the truth?[0:11:26] Dr. Lex Fridman: When you're given an image of a cat, How do you provide to the computer that this image contains a cat? Do you just say the entire image is a picture of a cat? Do you do What's very commonly been done, which is a bounding box, you have a very crude box around the cat's face saying this is a cat. Do you do Semantic segmentation, mind you, this is a two d image of a cat. So it's not a the computer knows nothing about our three-dimensional world.[0:11:55] Dr. Lex Fridman: It's just looking at a set of pixels. So, semantic segmentation is drawing a nice, very crisp outline around the cat and saying that's a cat. That's really difficult to provide that truth, and the one of the fundamental open questions in computer vision is, is that even a good representation of the truth? Now there's another contrasting set of ideas. Their attention, their overlapping Is, what's used to be called unsupervised learning, what's commonly now called self supervised learning, which is trying to get less and less Unless human supervision into the into, into the task.[0:12:33] Dr. Lex Fridman: So self supervised learning is, Moore, has been very successful in the domain of, language model, natural language processing, and now more and more is being successful in computer vision task. And was the idea there is let the machine without any ground truth annotation just Look at pictures on the Internet or look at text on the Internet and try to learn something, generalizable about the ideas that are at the core of language or at the core of vision. And based on that, we humans, at its best, like to call that common sense. So with this, we have this giant base of knowledge on top of which we build more sophisticated knowledge. We have this kinda common sense knowledge.[0:13:21] Dr. Lex Fridman: And so the idea with self supervised learning is to build this common sense knowledge about what are the fundamental visual ideas That make up a cat and a dog and all those kinds of things without ever having human supervision. The the dream there is The you just you just let an AI system that's self supervised, run around the Internet for a while, watch YouTube videos for millions and millions of hours, And without any supervision, be primed and ready to actually learn with very few examples once the human is able to show up. We think of, children in this way, human children, is your parents only give 1 or 2 examples to teach a concept. The the dream with self supervised learning is that will be the same with with, machines, that they would watch Millions of hours of, YouTube videos and then come to a human and be able to understand when the human shows them this is a cat. Like, remember this, a cat.[0:14:20] Dr. Lex Fridman: They will understand that a cat is not just a thing with pointy ears or a cat a cat is a thing that's orange Or as furry, they'll they'll see something more fundamental that we humans might not actually be able to introspect and understand. Like, if I asked you what makes a cat versus a dog, You wouldn't probably not be able to answer that, but if I showed you, brought you a cat and a dog, you'd be able to tell the difference. What are the ideas that Your brain uses to make that difference. That's the whole dream with self supervised learning is they would be able to learn that on its own, that Set of common sense knowledge that's able to tell the difference. And then there's, like, a lot of incredible uses of self supervised learning, very weirdly called self play mechanism.[0:15:07] Dr. Lex Fridman: That's the mechanism behind the, The reinforcement learning successes of, the systems that wanted, Go at, AlphaZero, that wanted chess.[0:15:18] Andrew Huberman: What oh, I see. That play games.[0:15:20] Dr. Lex Fridman: That play games.[0:15:21] Andrew Huberman: Got it.[0:15:21] Dr. Lex Fridman: So the idea of self play is probably applies, to other domains than just games, It's a system that just plays against itself. And this is fascinating in all kinds of domains, but, It knows nothing in the beginning, and the whole idea is it creates a bunch of mutations of itself and plays against those, versions of itself. And the fascinating thing is when you play against systems that are a little bit better than you, You start to get better yourself. Like, learning that's how learning happens. That's true for martial arts.[0:15:57] Dr. Lex Fridman: That's true in a lot of cases Where you want to be interacting with with, systems that are just a little better than you. And then through this process of interacting with systems just a little better than you, You start following this process where everybody starts getting better and better and better and better until you are several orders of magnitude better than the world champion in chess, for example. It's fascinating because it's like a runaway system. One of the most terrifying and exciting things that, David Silver, the creator of AlphaGo and AlphaZero, one of the Leaders of the team said, to me is, they haven't found the ceiling for alpha zero, Meaning, it could just arbitrarily keep improving. Now in the realm of chess, that doesn't matter to us that it's like it just ran away with the game of chess.[0:16:45] Dr. Lex Fridman: Like, it's, like, just So much better than humans. But the question is what if you can create that in the realm that does have a A bigger, deeper effect on human beings, on societies, that could be a terrifying process. To me, it's an exciting process if you supervise it correctly. If you inject, if, what's called value alignment. You, You make sure that the goals that the AI is optimizing is aligned with human beings and human societies.[0:17:17] Dr. Lex Fridman: There's a lot of fascinating things to talk about within the, specifics of neural networks and all the problems that people are are working on. But I would say the really big exciting one is self supervised learning. We're trying to get less and less human supervision, less and less human supervision of neural networks. And, also, just a comment, and I'll shut up.[0:17:41] Andrew Huberman: No. Please keep going. I'm I'm learning. I have questions, but I'm learning. So please keep going.[0:17:46] Dr. Lex Fridman: So that to me, what's exciting is not the theory, it's always the application. One of the most exciting applications of artificial intelligence, Specifically, neural networks and machine learning is Tesla autopilot. So these are systems that are working in the real world. This isn't an academic exercise. This Human lives at stake.[0:18:05] Dr. Lex Fridman: This is safety critical.[0:18:07] Andrew Huberman: These are automated vehicles. Autonomous vehicles.[0:18:09] Dr. Lex Fridman: Semi autonomous. We wanna be Okay. We We've gone through wars on these topics.[0:18:14] Andrew Huberman: Semi autonomous with you.[0:18:16] Dr. Lex Fridman: Semi autonomous. So even though it's called the FSD, Full self driving, it is currently not fully autonomous, meaning human supervision is required. So human is tasked with overseeing the systems. In fact, liability wise, the human is always responsible. This is a human factious psychology question, which is fascinating.[0:18:39] Dr. Lex Fridman: I'm Fascinated by the the the whole space, which is a whole another space of human robot interaction. When AI Systems and humans work together to accomplish task. That dance to me is, is one of the smaller communities, but I think will be one of the most important open problems once they're solved is how do humans and robots dance together. To me, Semiotonomous driving is one of those spaces. So for, for Elon, for example, he doesn't see it that way.[0:19:11] Dr. Lex Fridman: He sees semi autonomous driving as a stepping stone towards fully autonomous driving. Like, Humans and robots can't dance well together. Like, humans and humans dance and robots and robots dance. Like, we need to This is an engineering problem. We need to design a perfect robot that solves this problem.[0:19:31] Dr. Lex Fridman: To me, forever, maybe this is not the case with driving, but The world is going to be full of problems where it's always humans and robots have to interact because I think Robots will always be flawed just like humans are going to be flawed, are flawed, and that's what makes life beautiful, that they're flawed. That's where learning happens, at the edge of your capabilities. So you always have to figure out how can Flawed robots and flawed humans interact together such that they, like, the the sum is bigger than the whole as opposed to focusing on just building the perfect robot. Mhmm. So the so that's one of the most exciting applications, I would say, of artificial intelligence to me It's autonomous driving and semi autonomous driving.[0:20:20] Dr. Lex Fridman: And that's a really good example of machine learning because those systems are constantly learning. And, there's a there's a process there that maybe I can comment on. The Andrej Karpathy, who's the head of autopilot, Calls it the data engine. And this process applies for a lot of machine learning, which is you build a system that's pretty good at doing stuff. You send any Screws up.[0:20:52] Dr. Lex Fridman: You know, we do this as kids that you know, you you have as adults. We do this as adults. Exactly. But we learn really quickly. But the The whole point, and this is the fascinating thing about driving, is you realize there's millions of edge cases.[0:21:07] Dr. Lex Fridman: There's just, like, weird situations that you did not expect. And so the data engine process is you collect those edge cases, and then you go back to the drawing board and learn from them. And so you have to create this data pipeline where all these cars, hundreds of thousands of cars, as you're driving around and something weird happens. And so whenever this weird detector fires, it's another important concept, that piece of data goes back, to the mothership for the for the training, for the retraining of the system. And through this data engine process, it keeps improving and getting better and better and better and better.[0:21:45] Dr. Lex Fridman: So, basically, you send out pretty clever AI systems out into the world and let it Find the edge cases. Let it screw up just enough to figure out where the edge cases are and then go back and learn from them and then send out that new version and keep updating that version.[0:22:04] Andrew Huberman: Is the updating done by humans?[0:22:06] Dr. Lex Fridman: The annotation is done by humans. The so you have to the weird examples come back, the edge cases, and you have to label what actually happened in there. There's also some Mechanisms for automatic automatically labeling, but mostly, I think you always have to rely on humans to improve, To understand what's happening in the weird weird cases. And then there's a lot of debate. And that's the other thing, what is artificial intelligence?[0:22:34] Dr. Lex Fridman: Which is a bunch of smart people having very different opinions about what is intelligence. So AI AI is basically a community of people who don't agree on anything.[0:22:43] Andrew Huberman: It seems to be the case. I'm you know? First of all, this is a beautiful description of terms that I've heard many times, among my colleagues at Stanford, at meetings, in the in the outside world, and, there's so many fascinating things. I have so many questions, but I do wanna ask 1 question about the culture of AI because it does seem to be a community where, at least as an outsider, Where it seems like there's very little consensus about what the terms and the operational definitions even mean, and there seems to be a lot of Blitting happening now of not just supervised and unsupervised learning, but these sort of, intermediate, conditions where Machines are autonomous, but then go back for more instruction. Like, kids go home from college during the summer and get a little you know, mom still feeds them, then eventually they leave the the nest kind of thing.[0:23:29] Andrew Huberman: Is there something in particular about engineers or about people in this, realm of engineering that you think lends itself to disagreement?[0:23:39] Dr. Lex Fridman: Yeah. I think, so so first of all, the more specific you get, the less disagreement there is. So there's a lot of disagreement about what is artificial intelligence, But there's less disagreement about what is machine learning and even less when you talk about active learning or machine teaching or, self supervised learning. And then when you get into, like, NLP language models or transformers, when you get into specific neural network architectures, There's less and less and less disagreement about those terms. So you might be hearing the disagreement from the high level terms, and that has to do with the fact that engineering, Especially when you're talking about intelligent systems is is, a little bit of an art and a science.[0:24:20] Dr. Lex Fridman: So the art part is, is the thing that creates disagreements because then you start having disagreements about How easy or difficult a particular problem is. For example, a lot of people disagree with Elon How difficult the problem of autonomous driving is, and and so but nobody knows. So there's a lot of disagreement about what are the limits of these techniques. And through that, the terminology also contains within it the, the disagreements. But overall, I think It's also a young science that also has to do with that.[0:24:58] Dr. Lex Fridman: So, like, it's not just engineering. It's that artificial intelligence Truly, as a large scale discipline where it's 1,000, tens of thousands, hundreds of thousands people working on it, huge amounts of money being made, that's a very recent thing. So we're trying to figure out those terms. And, of course, there's egos and personalities and a lot of fame to be made, you know, Like, the the term deep learning, for example. Neural networks have been around for many, many decades since the sixties.[0:25:28] Dr. Lex Fridman: You can argue since the forties. So there was a rebranding of neural networks into the word deep learning, term deep learning, that was part of the Reinvigoration of the field, but it's really the same exact thing.[0:25:42] Andrew Huberman: I didn't know that. I mean, I grew up in the age of neuroscience when neural networks, were discussed. Computational neuroscience and theoretical neuroscience, they had their own journals. It wasn't actually taken terribly seriously by experimentalists until a few years ago. I would say about 5 to 7 years ago, excellent theoretical neuroscientists like Larry Abbott and, other, I have colleagues certainly at Stanford as well that People started paying attention to computational methods, but these terms, neural networks, computational methods, I actually didn't know that neural network works and deep learning Where, those have now become kind of synonymous.[0:26:19] Dr. Lex Fridman: No. They were always what no. They're always the same thing.[0:26:22] Andrew Huberman: Interesting.[0:26:23] Dr. Lex Fridman: It was so I'm[0:26:24] Andrew Huberman: a neuroscientist, and I didn't know that.[0:26:25] Dr. Lex Fridman: So well, because neural networks probably mean something else in neuroscience. Not something else, but a little different flavor depending on the field. And that's fascinating too Because neuroscience and AI, people have started, working together and dancing a lot more, in the recent, I would say, probably decade. Oh, machines are going into the[0:26:42] Andrew Huberman: brain. Are going into the brain. I I have a couple questions, but one thing that I'm sort of fixated on that I find incredibly interesting is this example, you gave of playing a game with a mutated version of yourself as a competitor. Yeah. I find that incredibly interesting as a kind of a parallel or a mirror for what happens when we try and learn as humans, which is we generate repetitions of whatever it is we're trying to learn, and we make errors.[0:27:13] Andrew Huberman: Occasionally, we succeed. In a simple example, for instance, of Trying to throw bull's eyes on a dartboard. Yeah. I'm gonna have errors, errors, errors. I'll probably miss the dartboard and maybe occasionally hit a bull's eye.[0:27:23] Andrew Huberman: And I don't know exactly what I just did. Right? But then, let's say I was playing darts against a version of myself where my I was wearing a visual prism. Like, my visual I had a visual defect. You learn certain things in that mode as well.[0:27:38] Andrew Huberman: You're saying that a machine can sort of mutate itself. Does the mutation always cause a deficiency that it needs to overcome? Because mutations in biology sometimes give us superpowers. Right? Occasionally, You'll get somebody who has better than 2020 vision, and they can see better than 99.9% of people out there.[0:27:56] Dr. Lex Fridman: Mhmm.[0:27:56] Andrew Huberman: So when you talk about a machine playing a Sheen playing a game against a mutated version of itself, is the mutation always a what we call a negative mutation, or a or an adaptive or a maladaptive mutation?[0:28:07] Dr. Lex Fridman: No. You you don't know until you get, so you mutate first and then figure out, and they compete against each other.[0:28:14] Andrew Huberman: So you're evolving your. The machine gets to evolve itself in real time.[0:28:18] Dr. Lex Fridman: Yeah. And I I think of it, which would be exciting, if you could actually do with humans, It's not just so, usually, you freeze a version of the system. So, really, you take today. And you make 10 clones of them. And then maybe you mutate, maybe not, and then you do a bunch of competitions of the android today.[0:28:42] Dr. Lex Fridman: Like, you fight to the death. Who wins last? So I love the idea of, like, creating a bunch of clones of myself from, like, from each of the day for the past year and just seeing who's going to be better at, like, podcasting or science or picking up chicks at a bar Or, I don't know, or competing in jiu jitsu. That's one way to do it. I mean, a lot of Lexus would have to die for that process, But that's essentially what happens is in reinforcement learning through the self play mechanisms, it's a graveyard of systems that didn't do that well.[0:29:14] Dr. Lex Fridman: And the the the surviving the the the good ones survive.[0:29:19] Andrew Huberman: Do do you think that, I mean, Darwin's theory of evolution Might have worked in some sense in this way, but at the population level. I mean, you get a bunch of birds with different shaped beaks and some birds have the shaped beak that allows them to get the seeds. I mean, it's a Trivial trivially simple example of Darwinian evolution, but I think it it it's it's correct if not, even though it's not exhaustive. Is that what you're referring to? You essentially that normally, this is done between members of a different species.[0:29:45] Andrew Huberman: Lots of different members of species have different traits, and some get selected for. But you could actually create multiple versions of yourself with different traits.[0:29:53] Dr. Lex Fridman: So with I should probably have said this, but, Perhaps it's implied, but machine learning, with reinforcement learning through these processes, one of the big requirements is to have an objective function, Loss function, a utility function, those are all different terms for the same thing. Is there's, like, an equation that says what's good, And and then you're trying to optimize that equation. So there's a clear goal for these systems.[0:30:20] Andrew Huberman: Like, because it's a Game. Like with chess, there's a there's a goal.[0:30:24] Dr. Lex Fridman: But for anything, anything you want machine learning to solve, there needs to be An objective function. In machine learning, it's usually called loss function that you're optimizing. The interesting thing about evolution, Complicated, of course, but the goal also seems to be evolving. Like, it's, I guess adaptation to the environment is the goal, But it's unclear you can convert that always. It's, like, survival of the fittest.[0:30:52] Dr. Lex Fridman: It's unclear what the fittest is. In machine learning, the starting point, and this is like what human ingenuity provides, Is that fitness function of what's good and what's bad, which it it it lets you know which of the systems is going to win. You need to have a equation like that. One of the fascinating things about humans is we figure out Objective functions for ourself. Like, we're, it's the meaning of life.[0:31:20] Dr. Lex Fridman: Like, why the hell are we here? And, a machine currently has to have, a hard coded statement about why.[0:31:29] Andrew Huberman: It has to have a meaning of Yeah. Artificial intelligence based life.[0:31:33] Dr. Lex Fridman: Right. It can't so, like, there's a lot of interesting explorations about, that A function being more about curiosity, about learning new things, and all that kind of stuff, but it's still hard coded. If you want a machine to be able to be good at stuff, It has to be given very clear statements of what good stuff means. That's one of the challenges of artificial intelligence is You have to formalize the in order to solve a problem, you have to formalize it, and you have to provide, both like the full sensory information, you have to be very clear about what is the data that's being collected, and You have to also be clear about the objective function. What is the goal that you're trying to reach?[0:32:18] Dr. Lex Fridman: And that's a very difficult thing for artificial intelligence.[0:32:22] Andrew Huberman: I love that you mentioned curiosity. I I'm sure this definition falls short in many ways, but I define curiosity as a A strong interest in knowing, something but without an attachment to the outcome. You know, it's sort of a, it's not it could be a random search, but it there's not really an emotional attachment. It's really just a desire to discover and unveil what's there without Hoping it's a, you know, a gold coin under a rock. You're just looking under rocks.[0:32:50] Andrew Huberman: Is that more or less how the, you know, within machine learning, it sounds like there are elements of Reward prediction and, you know, rewards, the machine has to know when it's done the right thing. So Can you make machines that are curious, or are the sorts of machines that you are describing curious by design?[0:33:10] Dr. Lex Fridman: Yeah. Curiosity is a kind of a Symptom, not, the goal. So what what happens is, one of the Big trade offs in reinforcement learning is this exploration versus exploitation. So when you know very little, it pays off to Explore a lot. Even suboptimal like, even trajectories that seem like they're not going to lead anywhere.[0:33:34] Dr. Lex Fridman: That's called exploration. The smarter and smarter and smarter you get, the the more emphasis you put on exploitation, meaning you, take the best solution. You take the best path. Now through that process, the exploration can look like curiosity by us humans, But it's really just trying to get out of the local optima of the thing that's already discovered. It's it's from an AI perspective, it's always looking To optimize the objective function, it it derives and we could talk about this a lot more.[0:34:08] Dr. Lex Fridman: But In terms of the tools of machine learning today, it derives no pleasure from just the curiosity of, like, I don't know. Discovery.[0:34:19] Andrew Huberman: So there's no dopamine for[0:34:20] Dr. Lex Fridman: There's no dopamine.[0:34:21] Andrew Huberman: There's no reward system chemical or, I guess electronic reward system.[0:34:27] Dr. Lex Fridman: That said, if you look at machine learning literature and reinforcement learning literature, They will use, like, deep mind. We use terms like dopamine. We're constantly trying to use the human brain to inspire totally new solutions to these problems. So they'll think like, how does dopamine function in the human brain and how can that lead to more, interesting ways to discover, optimal solutions. But ultimately, currently, the, there has to be a a formal objective function.[0:34:57] Dr. Lex Fridman: You could argue that humans also has a set of objective functions we're trying to optimize. We're just not able to introspect them.[0:35:04] Andrew Huberman: We yeah. We don't actually know what we're Looking for and seeking and doing.[0:35:09] Dr. Lex Fridman: Well, like, Lisa Feldman Barrett, you spoken with, at least on Instagram. I hope you[0:35:14] Andrew Huberman: through you. Yeah.[0:35:14] Dr. Lex Fridman: Yeah. I hope you actually have her on this podcast. That[0:35:17] Andrew Huberman: was terrific.[0:35:18] Dr. Lex Fridman: So, she has a very, it has to do with homeostasis like that. Basically, there's a very dumb objective function that the brain is trying to optimize, like, to keep, like, body temperature the same. Like, there's a very dumb kind of Optimization function happening. And then what we humans do with our fancy consciousness and cognitive abilities is we tell stories to ourselves we can have nice podcasts, but, really, it's the brain trying to maintain, just like healthy state, I guess. That that's fascinating.[0:35:51] Dr. Lex Fridman: I I also see the human brain and and I hope artificial intelligence systems as Not just systems that solve problems or optimize a goal, but also storytellers. I think there's a power to telling stories. We tell stories to each other. That's what communication is. Like, when you're alone, that's when you solve problems.[0:36:16] Dr. Lex Fridman: That that's when it makes sense to talk about solving problems. But when you're a community, the capability to communicate, tell stories, Whole share ideas in such a way that those ideas are stable over a long period of time. That's like that's Being a charismatic storyteller, and I think both humans are very good at this, arguably, I would I would argue that's why We are who we are is we're great storytellers, and then AI, I hope, will also become that. So it's not just about Being able to solve problems with a clear objective function, it's afterwards, be able to tell, like, a way better like, make up a way better about why you did something or why you failed.[0:36:55] Andrew Huberman: So you think that, robots or and or machines of of some sort are going to start telling humans Stories.[0:37:02] Dr. Lex Fridman: Well, definitely. So the technical field for that is called explainable AI. Explainable artificial intelligence is Trying to figure out how you get the AI system to explain to us humans why the hell it failed or why it succeeded Or, there's a lot of different sort of versions of this or to visualize how it understands the world. That's a really difficult problem, especially when you're on networks that are, famously opaque, that they we don't understand in many cases why a particular neural network does What it does so well and, to try to figure out where it's going to fail, that requires the AI to explain itself. There's a huge amount of money.[0:37:49] Dr. Lex Fridman: Like, there's a huge amount of money in this, especially from government funding and so on. Because if you wanna deploy, AI systems in the real world, we humans at least wanna Ask it a question like, why the hell did you do that? Like, in a dark way, why did you just kill that person? Right? Like, if a car ran over a person, we want to understand why that happened.[0:38:13] Dr. Lex Fridman: And, now, again, we're sometimes very unfair to AI systems because we humans can't often not explain why very well. But that's the field of, explainable AI. That's very people are very interested in because the more and more we rely on AI systems, like The the Twitter recommender system, that AI algorithm, that's, I would say, impacting elections, perhaps starting wars or at least military conflict, That's that algorithm, we wanna ask that algorithm. First of all, do you know what the hell you're doing? Do you know Do you understand the society level effects you're having, and can you explain the possible other trajectories?[0:38:55] Dr. Lex Fridman: Like, we would have that kind of conversation with a human. Wanna be able to do that with an AI. And on my own personal level, I think it would be nice to talk to AI systems for stupid stuff, Like, robots, when they fail to,[0:39:11] Andrew Huberman: Why'd you fall down the stairs?[0:39:13] Dr. Lex Fridman: Yeah. But, not an engineering question, But almost like, endearing question. Like like, I'm looking for if I fell and you and I were hanging out, I don't think you need an explanation exactly what were the dynamic like, what was the underactuated system problem here? Like, Right. What what was the texture of the floor or so on?[0:39:36] Dr. Lex Fridman: Or, like, what was the No.[0:39:37] Andrew Huberman: I wanna know what you're thinking.[0:39:39] Dr. Lex Fridman: That or you might joke about, like, you're drunk again. Go home or something. Like, there could be humor in it. That that's an opportunity. Like, storytelling isn't just explanation of what happened.[0:39:51] Dr. Lex Fridman: It's Something that, makes people laugh, makes people fall in love, makes people dream, and understand things in a way that Poetry makes people understand things as opposed to a rigorous log of, where every sensor was, where every, actuator was.[0:40:09] Andrew Huberman: I mean, I find this incredible because, you know, one of the hallmarks of severe autism spectrum disorders is, a report of Experience from the autistic person that is very much a catalog of of action steps. It's like, how do you feel today? And they'll say, I got up and I did this and then I did this and I did this, and it's not at all the way that a a person with who doesn't have autism spectrum disorder would would respond. And The way you describe these machines has so much human, has so much humanism or so much of of a human and biological element, But I realized that we are talking about machines. I I wanna make sure that I understand if there's a distinction between a machine that learns, a machine with artificial intelligence, and a robot.[0:41:00] Andrew Huberman: Like, at what point does a machine become a Robot. So if I have a ballpoint pen, assuming I wouldn't call that a robot. But if my ballpoint pen, can come to me when it's on when I move to the opposite side of the table, if it's moves by whatever mechanism, At that point, does it become a robot?[0:41:20] Dr. Lex Fridman: Okay. There's a 1000000 ways to explore this question. It's a fascinating one. So first of all, there's a question of What is life? Like, how do you know something is a living form or not?[0:41:31] Dr. Lex Fridman: Mhmm. And it's similar to the question of when does sort of a maybe a Cold computational system becomes a, we're already loading these words with a lot of meaning, robot and machine. But So, one, I think movement is is important, but but that's kind of a boring idea that a robot It's just a machine that's able to act in the world. So one, artificial intelligence could be both Just the thinking thing, which I think is what machine learning is, and also the acting thing, which is what we usually think about robots. So robots are the things that have a perception system that's able to take in the world however you define the world, is able to think and learn and do whatever the hell it does inside, And then act on the world.[0:42:18] Dr. Lex Fridman: So that's the difference between maybe an AI system or a machine and a robot. It's something that's able a robot is something that's able to Perceive the world and act in the world.[0:42:28] Andrew Huberman: So it could be through language or sound or it could be through movement or both.[0:42:32] Dr. Lex Fridman: Yeah. And I think it could also be in the digital space As long as there's a aspect of entity that's inside the machine and a world that's outside the machine and there's a sense in which the machine is sensing that world and acting in it.[0:42:49] Andrew Huberman: So we could for instance, there could be a version of a robot according to your the definition that I think you're providing, Where the robot, I where I go to sleep at night and this robot goes and forages for information that it thinks I want to see loaded onto my desktop There was no movement of that machine. There was no language, but it essentially has movement in in cyberspace.[0:43:11] Dr. Lex Fridman: Yeah. There's a distinction that I think is Important in that there's a there's a element of it being an entity, Whether it's in the digital or the physical space. So when you have something like Alexa in your home, Most of the, speech recognition, most of what Alexa is doing is constantly being sent back to the mothership. The when Alexa is there on its own, that's, to me, a robot When it's there interacting with the world, when it's simply a finger of the main mothership, that's not then the Lexus is not a robot, then it's just an interaction device. Then maybe the main Amazon Alexa AI big, big system is the robot.[0:44:04] Dr. Lex Fridman: So the That's important because there's some element to us humans, I think, where we want there to be an entity, whether in the digital or the physical space. That's where ideas of consciousness come in and, all those kinds of things that we project our understanding what it means to be a being. And so to take that further, when does a machine become a robot, I think there's a there's a special moment there's a special moment in a person's life, in in a robot's life where it surprises you. I think surprise is a really powerful thing where you know how the thing works and yet it surprises you. That that's a magical moment for us humans.[0:44:51] Dr. Lex Fridman: So whether it's a chess playing program that does something that you haven't seen before, that makes people smile, Like, Those moments happen with AlphaZero for the first time in chess playing where grandmasters were really surprised by a move. They didn't understand the move, and then they studied and studied and then then they understood it. But that moment of surprise, that's for grandmasters in chess. I find that moment of surprise really powerful, really magical in just everyday life.[0:45:23] Andrew Huberman: Because it supersedes the the human brain in that moment?[0:45:27] Dr. Lex Fridman: Not, so it's not supersedes, like, outperforms, but surprises you in a positive sense. Like, I didn't I didn't think you could do that. I I didn't think that you had that in you. And, I think that moment is a big transition for a robot from a from a moment of being a servant that that accomplishes a particular task With some level of accuracy, with some, rate of of failure to an entity, a being that's struggling just like you are in world. And that that's a really important moment that I think, you're not gonna find many people in the AI community that talk like I just did.[0:46:11] Dr. Lex Fridman: I I'm not speaking like some philosopher or some hippie. I'm speaking from purely engineering perspective. I think it's really important for robots to become entities and explore that as a real engineering problem as opposed to, everybody treats robots in the robotics community. They don't even call him a he or she. They don't give him try to avoid giving him names.[0:46:32] Dr. Lex Fridman: They really want to see it like a system, like a a servant. They see it as a servant. He's trying to accomplish a task. To me and I don't think I'm just romanticizing the notion. I think it's a being.[0:46:46] Dr. Lex Fridman: It's currently perhaps a dumb being, but in the in the long arc of, History, humans are pretty dumb beings too.[0:46:54] Andrew Huberman: So I I would agree with that statement.[0:46:57] Dr. Lex Fridman: So I I tend to really want to explore this, treating robots really as, as entities. The yeah. And so, like, anthropomorphization, which is the sort of the act of looking at a inanimate object and projecting onto it lifelike features. I think Robotics generally sees that, as a as a negative. I see it as a superpower.[0:47:24] Dr. Lex Fridman: Like, that we need to use that.[0:47:26] Andrew Huberman: Well, I'm struck by how that really grabs on to the relationship between Human and machine or human and robot. So just the simple question is and I think you've already told us the answer, but Does interacting with a robot change you? Does it in other words, do do we develop relationships to robots?[0:47:47] Dr. Lex Fridman: Yeah. I think I definitely I definitely think so. I think, I think the moment you see a robot or AI systems as more than just servants But, entities, they begin to change you just like good friends do, just like, relationships, just like Other humans. I think, for that, you have to have certain aspects of that interaction, like the robot's ability to, say no, To, to have its own sense of identity, to have its own set of goals that's not constantly serving you, but instead trying to understand the world and, do that dance of understanding through communication with you. So I I definitely think there's a I mean, I have a lot of thoughts about this as you may know, and that's at the core of my lifelong dream, actually, of what I wanna do, which is, I believe that Most people have, a notion of loneliness in them that we haven't discovered that that we haven't explored, I should say.[0:48:53] Dr. Lex Fridman: And I see AI systems as helping us explore that so that we can become better humans, better people towards each other. So I think that connection between human and AI, human and robot, is It's not only possible, but, will help us understand ourselves in ways that are like several orders of magnitude, deeper than we ever could have imagined. I tend to believe that well, I have, very wild levels of belief in terms of how impactful that would be. Nice.[0:49:35] Andrew Huberman: So, when I think about human relationships, I I don't, always break them down into variables, but we could explore a a few of those variables and see how they map To human robot relationships. One is just time. Right? If you spend zero time with another person, at all in In cyberspace or on the phone or in person, you essentially have no relationship to them. If you spend a lot of time, you have a relationship.[0:49:59] Andrew Huberman: This is obvious, but I guess one variable would be time. How much time you Spend with the other entity, robot or human. The other would be, wins and successes. You know, you enjoy successes together. I'll give a absolutely trivial example of this in in a moment, but, the other would be failures.[0:50:19] Andrew Huberman: When you struggle with somebody, whether or not you struggle between one another, you disagree. Like, I was really struck by the fact that you said that robots saying no. I've never thought about a robot saying no to me, but there it is.[0:50:31] Dr. Lex Fridman: I look I look forward to you being one of the first People are sending us robots.[0:50:35] Andrew Huberman: So do I. So there's there's struggle. You grow you know, when you struggle with somebody, you grow closer. Sometimes the struggles are Imposed between those 2 people, so called trauma bonding, they call it in the whole, psychology literature and pop psychology literature. But In any case, I could imagine so time, successes together, struggle together, and then just, Peaceful time, hanging out at home, watching watching movies, waking up near one another.[0:51:06] Andrew Huberman: Here we're breaking down the kind of elements of relationships of any kind. So do you think that these elements Apply to robot human relationships. And if so, then I could see how if the If the robot is its own entity and has some autonomy in terms of how it reacts to you, it's not just there just to serve you. It's not just a servant. It actually has opinions and can tell you when maybe your thinking is flawed or your actions are flawed.[0:51:35] Andrew Huberman: It can also leave it can Could also leave. So I've never conceptualized robot human interactions this way. So tell me more about how this might look. Are we thinking about, A human appearing robot. I know you and I have both had intense relationships to our we have separate dogs, obviously but to to animals, this sounds a lot like human animal interaction.[0:51:59] Andrew Huberman: So what is the ideal human robot relationship?[0:52:04] Dr. Lex Fridman: So there's a lot to be said here, but you actually pinpointed one of the big, big first steps, which is, say, do you have time? And it's a huge limitation in machine learning community currently. As this now we're back to, like, the actual details. Lifelong learning is a is a is a problem space that, focuses on how AI Systems can learn over a long period of time. What's currently most machine learning systems are not able to do is to all of the things you've listed under time, the successes, the failures, or just chilling together watching movies, AI systems are not able to Do that, which is all the beautiful, magical moments that I believe are the days filled with.[0:52:53] Dr. Lex Fridman: They're not able to keep track of those together with you.[0:52:56] Andrew Huberman: There because they can't move with you and be with you. No.[0:52:59] Dr. Lex Fridman: No. No. Like, literally, we don't have the the the techniques to to to do the learning, the actual learning of containing those moments. Current machine learning systems are really focused on understanding the world in the following way. It's more like the perception system, Like, looking around, understand, like, what's in the scene, that there's a bunch of people sitting down, That there is, cameras and microphones, that there's a table, understand that.[0:53:27] Dr. Lex Fridman: But the fact that we shared this moment of talking today And still remember that for next time you're for, like, next time you're doing something, remember that this moment happened. We don't know how to do that, technique. Right? This is what I'm this is what I'm, hoping to innovate on as I think it's a very, very important Component of what it means to create a deep relationship, that sharing of moments together.[0:53:52] Andrew Huberman: Could you post a photo of you and the robot, like Self selfie with robot Yeah. And the robot sees that image and recognizes that was time spent. There was a there were smiles or there were tears. Yeah. And create some sort of, metric of of emotional depth in the relationship and update its behavior.[0:54:11] Andrew Huberman: So could it it text you in the middle of the night and say, why haven't you texted me back?[0:54:16] Dr. Lex Fridman: Well, yes. All of those things. But the we can we can dig into that. But I think that time element, forget everything else, just sharing moments together, that changes everything. I believe that changes everything.[0:54:30] Dr. Lex Fridman: There's Specific things that are more in terms of systems that can explain you, it's it's more technical and probably a little bit offline because I have Kind of wild ideas how that can revolutionize social networks and, and operating systems. But the point is that element alone. Forget all the other things we're talking about, like emotions, saying no, all that. Just remember, Sharing moments together would change everything. We don't currently have systems that, share Share moments together.[0:55:05] Dr. Lex Fridman: Like, even just you and your fridge, just all those times you went late at night and and ate the thing you shouldn't have eaten, That was a secret moment you had with your refrigerator. You shared that moment, that darkness or that beautiful moment where you were just, you know, Like, heartbroken for some reason, you're eating that ice cream or whatever, that's a special moment. And that refrigerator was there for you, And the fact that it missed the opportunity to remember that, is is is tragic. And once it does remember that, I think you're gonna be very attached to the refrigerator. You you're gonna go through some through some hell with that refrigerator.[0:55:45] Dr. Lex Fridman: Most of us have, like, In in a in a developed world, have weird relationships with food. Right? So you can go through some, some deep moments of Moments of trauma and triumph with food, and at the core of that is the refrigerator. So a smart refrigerator, I believe, would, change Society, not just the refrigerator, but the these ideas in the systems all around us. So that I I just wanna comment on how powerful that idea of time is.[0:56:14] Dr. Lex Fridman: And then there's a bunch of elements of actual interaction of Allowing you as a human to feel like you're being heard, truly heard, truly understood That we human like, deep friendship is like that, I think, but we're still there's still an element of selfishness. There's still an element of, Not really being able to understand another human. And a lot of the times when you're going through trauma together through difficult times and through successes, You're actually starting to get that inkling of understanding of each other, but I think that could be done more aggressively, more efficiently. Like, if you think of a great therapist, I think I've never actually been to a therapist, but I'm a believer. I used to wanna be a psychiatrist.[0:57:04] Andrew Huberman: Do Russians go to therapists? No. They don't. They don't.[0:57:08] Dr. Lex Fridman: And, if they do, the therapists don't live to tell the story. No. I, I I I do believe in talk there, which friendship is to me is is talk therapy or, like, it's, like it's you don't necessarily need to talk. It's like just connecting, through in the space of ideas, in the space of experiences. And I think there's a lot of ideas of how to make AI systems to be able to Ask the right questions and truly hear another human.[0:57:37] Dr. Lex Fridman: This is what we try to do with podcasting. Right? I think there's ways to do that with AI. But Above all else, just remembering the collection of moments that make up the day, the week, the months. I think, you maybe have some of this as well.[0:57:55] Dr. Lex Fridman: Some of my closest friends still are the friends from high school. That's time. We've been through a bunch of shit together, and that like, we've we're very different people. But just the fact that we've been through that and we remember those moments, and those moments somehow create a depth of connection like nothing else, Like you and your refrigerator.[0:58:16] Andrew Huberman: I I love that because the I had a my graduate adviser, unfortunately, she passed away. But when she passed away, somebody That it hurt, at her memorial, you know, all these amazing things she had done, etcetera. And then her kids got up there, And she had young children that I knew as they were when she was pregnant with them. And so it was really, you know, you're even now I can feel like your heart gets heavy thinking about this. They're gonna grow up without their mother, And it was really amazing.[0:58:42] Andrew Huberman: Very very strong, young girls and now young women. And what they said was incredible. They said what they really appreciated most about their mother who was an amazing person is all the unstructured time they spent together.[0:58:59] Dr. Lex Fridman: Mhmm.[0:58:59] Andrew Huberman: So it wasn't the trips to the zoo. It wasn't, you know, oh, you know, she woke up at 5 in the morning and drove us to school. She did all those things too. 2 hour commute in each direction. It was incredible.[0:59:08] Andrew Huberman: Ran a lab, etcetera, but it was the unstructured time. So on the passing of their mother, that that's what they remembered was the the biggest give and what bonded them to her was all the time where they just kind of hung out. And the way you describe the relationship to a refrigerator Is, so I wanna say humanlike, but I'm almost reluctant to say that because what I'm realizing as we're talking is that What we think of as humanlike might actually be the, a lower form of relationship. There may be relationships that are far better than the sorts of relationships that we can conceive in our minds right now based on what these machine relationship interactions could teach us. Do I have that right?[0:59:52] Dr. Lex Fridman: Yeah. I think so. I think there's no reason to see machines as, somehow, incapable of teaching us something that's deeply human. I I don't think, humans have a monopoly on that. Think we understand ourselves very poorly, and we need to to have the kind of, prompting from, from a machine.[1:00:14] Dr. Lex Fridman: And definitely part of that is just remembering the moments remembering the moments. I'm you know? I think the unstructured time together, I wonder if it's quite so unstructured. That's like calling this podcast unstructured time.[1:00:30] Andrew Huberman: Maybe what they meant was, it wasn't a big outing. It wasn't as there was no specific goal, but a goal was created through the lack of a goal. Like, where you just hang out and then you start playing, you know, thumb war, and you end up playing thumb war for an hour. There so it's it's the structure emerges from lack of Structure.[1:00:48] Dr. Lex Fridman: No. But the thing is, the moments there's something about those times that create special moments, And, I think those could be optimized for. I think we think of, like, a big outing as, I don't know, going to 6 flags or something or some big, The Grand Canyon or go into some, I don't know. The the I think we would need to we don't quite yet understand as humans what creates magical Moments. I think that it's possible to optimize a lot of those things.[1:01:18] Dr. Lex Fridman: And perhaps, like, podcasting is helping people discover that, like, maybe the thing we wanna optimize for isn't necessarily, like, some, sexy, like, quick clips. Maybe what we want is long form authenticity, depth depth. So we were trying to figure that out, certainly from a deep connection between Between humans and humans and AI systems, I think long conversations or long periods of communication Over a a series of moments like minute, perhaps seemingly insignificant to the big ones, the big success the big, failures, those are all just stitching those together and talking throughout, I think that's, the formula for a really, really deep connection that from a like, a very specific engineering perspective is, I think a fascinating open problem that hasn't been really worked on very much. And for me, from a if I have the guts And, I mean, there's a lot of things to say, but one of it is guts. I'll build a startup around it.[1:02:29] Andrew Huberman: Yeah. So let let's talk about this startup, and let's talk about the the dream. You've mentioned this dream before in our previous conversations. Always as little hints Dropped here and there. Just, for anyone listening, there's never been an offline conversation about this dream.[1:02:43] Andrew Huberman: I'm not privy to anything, except what Lex says now. And I realized that there's no way to capture the full essence of a dream in any kind of verbal statement in a way that captures all of it. But what is the what is this dream that you've referred to now Several times, when we've sat down together and talked on the phone, maybe it's this company. Maybe it's something distinct. If you feel comfortable, It'd be great if you could share a little bit about what that is.[1:03:13] Dr. Lex Fridman: Sure. So the the way people express long term vision, I've noticed is quite different. Like, Elon is an example of somebody who can very crisply say exactly what the goal is. Also has to do with the fact the problems he's Solving have nothing to do with humans. So my long term vision is a little bit more difficult to Expressing words, I've noticed as I've tried.[1:03:40] Dr. Lex Fridman: It could be my brain's failure, but there's a ways to sneak up to it. So let me just say a few things. Early on in life, in in and also in the recent years, I've interacted with a few robots Where I understood there's magic there, and that magic could be shared by 1,000,000 if it's, brought to light. When I first met Spot from Boston Dynamics, I realized there's magic there that nobody else is seeing. It's the dog.[1:04:11] Dr. Lex Fridman: It's the dog. Sorry. The Spot is the 4 legged, robot from Boston Dynamics. Some people might have seen it. It's this yellow dog.[1:04:20] Dr. Lex Fridman: And, You know, sometimes in in in life, you just notice something that just grabs you. And I believe that this is something that This magic is something that could be every single device in the world. The the way that I think, maybe Steve Jobs Thought about the personal computer. Woz didn't think about the personal computer this way, but Steve did, which is like He thought that the personal computer should be as thin as a sheet of paper, and everybody should have 1. I mean, this idea, I think It is heartbreaking that, we're getting the world is being filled up with machines They're soulless, and I think every one of them can have that same magic.[1:05:10] Dr. Lex Fridman: One of the things that Also inspired me in terms of a startup is that magic can be engineered much easier than I thought. That's my intuition with everything I've ever Built and worked on. So the the dream is to add a bit of that magic in every single computing in the world. So the way that Windows operating system for a long time was, the primary operating system everybody interacted with. They built apps On top of it, I think this, is something that should be as a layer.[1:05:45] Dr. Lex Fridman: It's almost as an operating system in, every device that humans interact with in the world. Now what that actually looks like, the actual dream when I was, especially, a kid, It didn't have this concrete form of a business. It had more of a a dream of, exploring Your own loneliness by interacting with machines, robots, this Deep connection between humans and robots was always a dream. And so for me, I'd love to see a world where there's every home as a robot And not a robot that washes the dishes, or a or a sex robot or, I don't know. I think of any kind of activity the robot can do, but more like a companion, a[1:06:34] Andrew Huberman: family member,[1:06:34] Dr. Lex Fridman: a family member, the way a dog is. Mhmm. But a dog that's able to speak your language too. So not just Connect the way a dog does by looking at you and looking away and almost like smiling with its soul in that kind of way, but also To actually understand what the hell like, why are you so excited about the successes? Like, understand the details.[1:06:58] Dr. Lex Fridman: Understand the traumas. And I I just think that had always filled me with excitement that I I could, with artificial intelligence, bring joy to a lot of people. More recently, I've been more and more Heartbroken to see the kind of division, derision, even hate that's Boiling up on, on the Internet through social networks, and I thought this kind of mechanism is exactly applicable in the context of social networks as well. So it's an operating system that, serves as your guide to, in on the Internet. One of the biggest problems with, YouTube and social networks currently is they're optimizing for engagement.[1:07:50] Dr. Lex Fridman: I think if you create AI systems that know each individual person, you're able to optimize for long term growth, for a long term happiness.[1:08:00] Andrew Huberman: Of the individual?[1:08:01] Dr. Lex Fridman: Of the individual. Of the individual. And, there's a lot of other things to say, which is the In order for AI systems to to learn everything about you, they need to collect they need to Just like you and I, when we talk offline, we're collecting data about each other, secrets about each other, the same way AI has to do that. And that allows you to and that requires you to rethink, ideas of ownership of data. I think Each individual should own all of their data and very easily be able to leave.[1:08:41] Dr. Lex Fridman: Just like AI systems can leave, Humans can disappear, and delete all of their data in a moment's notice, which is actually better than we humans can do. Because once we load the data into each other, it's there. I think it's, very important to be both, Give people complete control over their data in order to establish trust that they can trust you. And the 2nd part of trust transparency. Whenever the data is used to make it very clear what is being used for and not clear in a lawyerly legal sense, but Clear in a way that people really understand what it's used for.[1:09:19] Dr. Lex Fridman: I believe when people have the ability to delete all their data and walk away and To know how the data is being used, I think they'll stay.[1:09:29] Andrew Huberman: The the possibility of a clean breakup is actually what will keep people together.[1:09:33] Dr. Lex Fridman: Yeah. I think so. I think Exactly. I think, a happy marriage requires the ability to divorce easily without the The the divorce and industrial complex or whatever is currently going on that then there's so much money to be made from lawyers and divorce. But, yeah, The ability to leave is what enables love, I think.[1:09:55] Andrew Huberman: It's interesting. I've heard the phrase, from a semi cynical friend that, marriage is the leading cause of divorce, But now we've heard that divorce or the possibility of divorce could be the leading cause of marriage.[1:10:06] Dr. Lex Fridman: Of a happy marriage. Good point. Of a happy marriage. So, yeah, so but there's there's a lot of details there, but the the big dream is that connection between AI system and a human. And I haven't You know, there's so much fear about artificial intelligence systems and about robots that I haven't quite found the right words to express that vision because the vision I have Is 1, it's not like some naive delusional vision of, like, technology's gonna save everybody.[1:10:36] Dr. Lex Fridman: It's I really do just have a positive view of ways AI systems can help humans explore themselves.[1:10:44] Andrew Huberman: I love that positivity, and I I agree that the the stance, everything is doomed is, equally bad To say that everything's gonna turn out alright, there has to be a dedicated effort. And clearly, you're, thinking about what that dedicated effort would look like. You mentioned 2, 2 aspects to this dream, and I wanna make sure that I understand where they, connect if they do or if these are independent streams. One was This, hypothetical robot family member or some other form of robot that would allow people to experience the kind of, delight that you experienced, many times and that you would like the world to to be able to have. And it's it's such a beautiful idea of of this give.[1:11:33] Andrew Huberman: And the other is social media or, social network platforms that, really serve individuals and and their best selves and their happiness and their growth. Is there crossover between those, or are these 2 parallel dreams?[1:11:46] Dr. Lex Fridman: It's a 100% the same thing. It's it's, difficult to kinda Explain without going through details, but maybe one easy way to explain the way I think about social networks is to create an AI system that's yours That's yours. It's not like Amazon, Alexa that's centralized. You own the data. It's it's it's like your little friend that becomes your representative on Twitter that that helps you find things that will make you Feel good that will, also challenge your thinking to make you grow, but not get to that, not let you get lost In the negative spiral of dopamine that that that gets you to be angry or most just get you to be not open to Learning.[1:12:34] Dr. Lex Fridman: And so that little representative is optimizing your long term health. And it's, I believe that that is not only good for human beings, it's also good for business. I think long term, you can make a lot of money, by challenging this idea that the only way to make money is, maximizing engagement. And with one of the things that people disagree with me on is they think Twitter is always going to win. Like, maximizing engagement is always going to win.[1:13:04] Dr. Lex Fridman: I don't think so. I think people have woken up now to understanding that, like, they don't always feel good. The the ones who are on Twitter a lot, That that they don't always feel good at the end of the week.[1:13:19] Andrew Huberman: I would love feedback from whatever this, creature, whatever. I can't I don't know what to call it. As to, you know, maybe at the end of the week, it would automatically unfollow some of the people that I follow because it realized Through some real really smart data about how I was feeling inside or how I was sleeping or something that, you know, that just wasn't good for me, but it might also put Things and people in front of me that, I ought to see. Is that Mhmm. Kind of[1:13:46] Dr. Lex Fridman: a[1:13:46] Andrew Huberman: sliver of what this what this looks like?[1:13:48] Dr. Lex Fridman: The whole point, because of the interaction, because Of sharing the moments and learning a lot about you, you're now able to understand What interactions led you to become a better version of yourself? Like, the person you yourself are happy with. This isn't you know, if you're into a flat Earth and you feel very good about it, that you believe the Earth is flat, Like, the the idea that you should censor, that is ridiculous. If it makes you feel good and you're becoming the best version of yourself, I think you should be getting as much flat earth as possible. Now it's also good to challenge your ideas, but not because the centralized, committee decided, but because you tell to the system that you like challenging your ideas, I think all of us do.[1:14:40] Dr. Lex Fridman: And then which, actually, YouTube doesn't do that well. Once you go down the flat earth rabbit hole, that's all you're gonna see. It's nice to get Some really powerful communicators to argue against flat earth, and it's nice to see that, for you and and potentially, at least long term, to expand your horizons, maybe the earth is is not flat. But if you continue to live your whole life thinking the earth is flat, I think and you're being a good father or son or daughter and, Like, you're being the best version of yourself and you're happy with yourself, I think, the earth is flat. So, like, I I I think this kind of idea and I'm just that kind of silly, ridiculous example because I don't like the idea of centralized Force is controlling what you can and can't see, but I also don't like this idea of, like, not Censoring anything.[1:15:39] Dr. Lex Fridman: Because that's always the biggest problem with that is this it's the there's a central decider. I think you yourself can decide what you wanna see and not, and it's good to have a companion that, reminds you that you felt shitty last time you did this or you felt good last time you did this.[1:15:58] Andrew Huberman: I mean, I feel like in every good story, there's a there's a guide or a companion that Flies out or forages a little bit further or a little bit differently and brings back information that helps us or at least tries to Steer us in the right direction.[1:16:11] Dr. Lex Fridman: So, actually, that's exactly, that's exactly the, what I'm thinking and what I've been working on. I I should mention there's a bunch of here. You you you see me up and down a little bit recently. So there's technically a lot of challenges here. This like with a lot of technologies, and the reason I'm talking about it on a podcast comfortably as opposed to working it in secret, is it's really hard, and maybe its time has not come.[1:16:41] Dr. Lex Fridman: And that's something you have to constantly struggle with in terms of, like, entrepreneurially as as a Startup. Like, I've also mentioned to you, maybe offline, I really don't care about money. I don't care about, Business success, all those kinds of things. So it it's a difficult decision to make how much of your time Do you wanna go all in here and give everything to this? It's a big roll of the dice because I've also realized that Working on some of these problems, both with the robotics and the technical side on in terms of, The the machine learning system that I'm describing, it's lonely.[1:17:25] Dr. Lex Fridman: It's really lonely Because, both on a personal level and a technical level. So on the technical level, I'm surrounded by people that kinda Doubt me, which I think all entrepreneurs go through. And they doubt you in the following sense. They They know how difficult it is. Like, the people that, the colleagues of mine, they know how difficult lifelong learning is.[1:17:52] Dr. Lex Fridman: They also know how difficult it is to build a system like this, to to build a competitive social network. And, in general, there's a kind of loneliness to Just working on something on your own for long periods of time, and you start to doubt whether, given that you don't have a track record of success Like, that's a big one. When you look in the mirror, especially when you're young but I still have that on most things. You look in the mirror. It's like and you have these big dreams.[1:18:26] Dr. Lex Fridman: How do you know you're how do you know you're actually as smart as you think you are? Like, how do you know you're going to be able to accomplish this dream? You have this ambition. You you sort of[1:18:37] Andrew Huberman: don't, but you're you're kinda pulling on a On a string hoping that there's a bigger ball of yarn.[1:18:43] Dr. Lex Fridman: Yeah. But you have this kind of intuition. I I've I think I pride myself in knowing what I'm good at because the reason I have that intuition is because I think I'm very good at knowing all the things I suck at, which is basically everything. So, like, whenever I notice, Like, wait a minute. I I'm kinda good at this, which is very rare for me.[1:19:08] Dr. Lex Fridman: I think, like, that that might be a ball of yarn worth pulling at. And the thing with in terms of engineering, systems that are able to interact with humans, I think I'm very good at that. And, because you we talk about podcasting and so on. I don't know if I'm very good at podcasting.[1:19:23] Andrew Huberman: You're very good at podcasting.[1:19:25] Dr. Lex Fridman: But I certainly don't. I think maybe, it is compelling to to for people to watch, a kindhearted idiot struggle with this with this form. Maybe that's what What what's compelling? But in terms of, like, actual being a good engineer of human robot interaction systems, I think I'm good. But It's hard to know until you do it, and then the world keeps telling you you're not.[1:19:51] Dr. Lex Fridman: And it's just it's full of doubt. It's really hard, and I've been struggling with that recently. It's it's kind of a fascinating struggle, but then that's where the Goggins thing comes in. It's like, Aside from the stay hard motherfucker is the, like, whenever you're struggling, that's a good sign That if you keep going, then you're going to be alone[1:20:13] Andrew Huberman: in the success. Right? Like, well, in your case, However, I I agree. And, actually, David had a post recently that I thought was among his many brilliant posts was one of The more brilliant about how, you know, he talked about this myth of the light at the end of the tunnel. And instead, what he replaced that Myth with was a concept that eventually your eyes adapt to the dark.[1:20:38] Andrew Huberman: That the tunnel it's not about a light at the end that it's about adapting to the car for the tunnel. He's very Goggins'[1:20:43] Dr. Lex Fridman: I love him so much.[1:20:44] Andrew Huberman: Yeah. You you guys share a lot in, a lot in common. Knowing you both a bit, you share a lot in common. But in this this loneliness and the and the pursuit of this dream, It seems to me it has a certain component to it that is extremely valuable, which is that the loneliness itself could serve as a driver to build the companion for the journey.[1:21:10] Dr. Lex Fridman: Well, I'm very deeply aware of that. So, Like, some people can, make because I talk about love a lot. I really love everything in this world and but I also love humans, friendship, and, Romantic, you know, like, even the cheesy stuff.[1:21:30] Andrew Huberman: Just You like romantic movies? Like, no.[1:21:32] Dr. Lex Fridman: And that's not the I'm not sure that's the it's it's, well, I got so much shit from Rogan about, like, was it the tango scene from Scent of a Woman? But, yeah, I find, like, a there's nothing better than a woman in a red dress, like, you know, just like classy[1:21:49] Andrew Huberman: should move to Argentina, my father. Yeah.[1:21:50] Dr. Lex Fridman: I'm You[1:21:51] Andrew Huberman: know, my father is Argentine. And you know what he said when I, when I went on your podcast for the first time? He said, He dresses well. Because in Argentina, the men go to a wedding or a party or something. You know, in the US, they by halfway through the night, 10 minutes in the night, all the jackets are off.[1:22:05] Andrew Huberman: Yeah.[1:22:05] Dr. Lex Fridman: It[1:22:05] Andrew Huberman: looks like everyone's undressing for the party they just got dressed up for. And he said, and he said, you know, I like the way he dresses. Then when I start he was talking about you. And then when he when I started my podcast, he said, why don't you wear a a real suit like your friend Lex?[1:22:20] Dr. Lex Fridman: I remember that. Thank you.[1:22:23] Andrew Huberman: But let's talk about, this this pursuit just a bit more because I think what you're talking about is is building a not just a solution for loneliness, but you've alluded to the loneliness as itself an important thing. I think you're right. I think within people, there is, like, caverns of thoughts and shame, but also just the desire to be, to have resonance, to to be seen and heard. And I don't even know that it's seen and heard through language. But these reservoirs are of loneliness, I think, they're well, they're interesting.[1:23:01] Andrew Huberman: Maybe you could comment a little bit about it because just as often as you talk about love, Haven't quantified it, but it seems that you talk about this loneliness. And maybe you just would if you're willing, you could you share a little bit more about that and and what What that feels like now in the pursuit of building this robot human relationship you've been let let me be direct. You've been spending a lot of time on Building a robot human relationship, where's that at? Oh,[1:23:31] Dr. Lex Fridman: in terms of business and in terms of systems? No. I'm talking about[1:23:34] Andrew Huberman: a specific robot. Oh, rope[1:23:37] Dr. Lex Fridman: So okay. I should I should mention a few things. So one is there's a startup where there's a idea where I hope millions of people can use. And then there's my own personal, like, almost like Frankenstein explorations with, with particular robots. So I'm very fascinated with the legged robots in my own, private sounds like dark, but, like, in in one n of 1 experiments to see if I can recreate the magic.[1:24:09] Dr. Lex Fridman: And, that's been I have a lot of really good already The perception systems and, control systems that are able to communicate affection in a dog like fashion. So I'm I'm in a really good place there. The stumbling blocks, which Also been part of my sadness recently is, that I also have to work with robotics companies that, you know, I gave so much of my Heart, soul, and love and appreciation towards Boston Dynamics, but Boston Dynamics is also, You know, as a company that has to make a lot of money and they have marketing teams, and they're, like, looking at this silly Russian kid in a suit and tie, it's like, what's he trying to do with all this love and robot interaction and dancing and so on? So there was a I think, Let's say for now, it's like when you break up with a girlfriend or something. Right now, we decided to part ways on this particular thing.[1:25:04] Dr. Lex Fridman: They're huge supporters of mine. They're huge fans. But On this particular thing, Boston Dynamics is not focusing on or interested in human robot interaction. In fact, their whole business currently is keep the robot as far away from humans as possible, because it's it's in in the industrial setting where it's doing monitoring in dangerous environments. It's almost like a remote security camera, essentially, is its application.[1:25:32] Dr. Lex Fridman: To me, I thought, it's still, even in those applications, exceptionally useful for the robot to be able to perceive humans, like, see humans, And to be able to, in a big map, localize where those humans are and have human intention. For example, Like this, I did this a lot of work with pedestrians for a robot to be able to anticipate what the hell the human is doing, like where it's walking. If you're Humans are not ballistics object. They're not just because you're walking this way one moment doesn't mean you'll keep walking that direction. You have to infer a lot of signals, especially with the head movement and the eye movement.[1:26:07] Dr. Lex Fridman: So I thought that's super interesting to explore, but, they didn't feel that. So I'll be working with a few other robotics companies that, are are, much more open to that kind of stuff, and they're super excited and fans of mine. Hopefully, Boston Dynamics, my first love, that getting back with an ex girlfriend will come around. But so the algorithmically, it's, I'm basically done there. The the rest is actually getting some of these companies to work with.[1:26:37] Dr. Lex Fridman: And then there's, for people who'd work with robots know that One thing is to write software that works, and the other is to have a real machine that actually works. And it it breaks down in all kinds of different ways that are fascinating, and So there's a big challenge there. But that's almost, it may sound a little bit confusing in the context of our previous discussion Because the previous discussion was more about the big dream, how I hoped to have millions of people enjoy this moment of magic. The this current discussion about a robot is something I personally really enjoy. It just brings me happiness.[1:27:16] Dr. Lex Fridman: I Really try to do now everything that just brings me joy. Maximize that because it's because robots are awesome. But, 2, given my, like, Little bit growing platform. I wanna use the opportunity to educate people. It's just it's like, robots are cool.[1:27:34] Dr. Lex Fridman: And if I think they're cool, I'll be able to, I hope, be able to communicate why they're cool to others. So the this little robot experiment is a little bit of research project too. There's a couple of publications the MIT folks are on that. But the the other is just to make some cool videos and explain to people how they actually work. And but as opposed to people being Scared of robots, they can be they could still be scared, but also excited.[1:27:59] Dr. Lex Fridman: Like, see the the dark side, the beautiful side, the magic What it means to bring, you know, for a machine to become a robot. I I want to, inspire people with that, but that's less It it's interesting because I think the big impact in terms of the dream does not have to do with embodied AI, so it does not need to have a body. I think, the refrigerator is enough that that for an AI system just to have a voice and to hear you, that's enough for loneliness. The embodiment is just,[1:28:36] Andrew Huberman: By embodiment, you mean the physical structure.[1:28:38] Dr. Lex Fridman: Physical instantiation of intelligence. It's a legged robot or even just a thing. I have a few other humanoid robot, A little humanoid robot, Mila, keep them on on the table. It's like walks around or even just like a mobile platform. They can just, like, Turn around and look at you.[1:28:57] Dr. Lex Fridman: It's like we mentioned with a pen, something that moves and can look at you. It's like that butter robot That's what, that asks what is my purpose, That that is really it's almost like art. There's something about a physical entity that moves around, that's able to look at you and interact with you that makes you wonder what it means to be human. It, like, challenges you to think, if I If that thing looks like he has consciousness, what the hell am I? And I like that feeling.[1:29:35] Dr. Lex Fridman: I think that's really useful for us. It's humbling for us humans. But that's less about, research. It's certainly less about business and more about exploring our own, our own selves and challenging others to think, like, to to, to think about what makes them human.[1:29:52] Andrew Huberman: I love this, desire to share the delight of an interaction with a robot. And as you describe it, I actually I find myself starting to crave that because, we all have those elements from childhood where or from adulthood where we experience something, we want other people Yeah. To feel that. And I think that you're right. I think a lot of people are scared of AI.[1:30:12] Andrew Huberman: I think a lot of people are scared of robots. My only experience in of a robotic like Thing, is my Roomba vacuum where it goes about actually, I was pretty good at picking up Costello's hair when he was shed, and then, and I was grateful for it. But then when it would when I was on a call or something and it would get caught on a on a wire or something, I would find myself getting upset with the Roomba. In that moment, I'm like, are you doing? You know?[1:30:36] Andrew Huberman: And I and, obviously, it's just doing what it does. Yeah. But but that's a kind of, mostly positive but slightly negative interaction. But what you're describing has so much more richness and layers of detail that I can only imagine what those relationships or like[1:30:53] Dr. Lex Fridman: Well, there's a few. Just a quick comment. So I've had they're currently in Boston. I have a bunch of Roombas from my robot. And I did this Experiment.[1:31:01] Andrew Huberman: Wait. How many Roombas? Sounds like a fleet of Roombas.[1:31:06] Dr. Lex Fridman: So I, probably 7 or 8. Well, that's[1:31:09] Andrew Huberman: a lot of Roombas. So This place is very clean.[1:31:12] Dr. Lex Fridman: Well, so this I'm kinda waiting. This this is, the the place we're currently in in Austin is way larger than I need, but, it's I basically got it so to to make sure I[1:31:25] Andrew Huberman: have room for robots. So you're gonna so you have these 7 or so Roombas. You deploy all 7 at once?[1:31:32] Dr. Lex Fridman: Oh, no. I do different experiments with them, different experiments with them. So one of the things I wanna mention is this is, I think there was a YouTube video that inspired me to try this, is, I got them to, to scream in pain and moan in pain, whenever they, were kicked or contacted. And I did that experiment to see how I would feel. I I meant to do, like, a YouTube video on it, but then it just seemed very cruel.[1:32:00] Andrew Huberman: Did any Roomba rights activists coming. Yeah.[1:32:02] Dr. Lex Fridman: That's smart. That like, I I think if I release that video, I think it's gonna make me look insane, which I know people know I'm already insane.[1:32:12] Andrew Huberman: Now you now you have to release the video.[1:32:14] Dr. Lex Fridman: Sure. Well, I I think maybe if I contextualize it by showing other robots Like, to show why this is fascinating because, ultimately, I felt like they were human almost immediately, And that display of pain was, what did that?[1:32:30] Andrew Huberman: Giving them a voice.[1:32:31] Dr. Lex Fridman: Giving them a voice, especially a voice of, dislike of of pain. Mhmm. I[1:32:37] Andrew Huberman: have to connect you to my friend Eddie Chang. He studies speech and language. He's a neurosurgeon, and we're lifelong friends. He, studies speech and language, but He described some of these, more primitive visceral vocalizations, cries, groans, Moans of delight, other sounds as well. Use your imagination.[1:32:59] Andrew Huberman: As such powerful rudders for The other for the emotions of other people.[1:33:04] Dr. Lex Fridman: Mhmm.[1:33:04] Andrew Huberman: And so I find it fascinating. I can't wait to see this video. Is that so is the video available online?[1:33:09] Dr. Lex Fridman: No. I haven't, I haven't recorded it. I just hit a bunch of Roombas that are able to scream and pain, in my Boston, in my Boston place. So I I, like, people are ready as[1:33:21] Andrew Huberman: as Next next podcast episode with, Lex that maybe we'll have that one.[1:33:26] Dr. Lex Fridman: Who knows? So the thing is, like, people I I've noticed because I talk so much about love, and it's really who I am. I think they wanna it, to a lot of people, it seems like there's there's There gotta be a dark person in there somewhere. And I thought if I release videos and Rumba's screaming, and they're like, yep. Yep.[1:33:43] Dr. Lex Fridman: That guy is definitely insane.[1:33:44] Andrew Huberman: What about, like, shouts of glee and delight. You could do that too. Right?[1:33:49] Dr. Lex Fridman: Well, I don't know how to I don't how do to me, delight is quiet. Right?[1:33:54] Andrew Huberman: I got You're Russian.[1:33:55] Dr. Lex Fridman: I don't I'm Americans[1:33:57] Andrew Huberman: are much Americans are much louder than Russians.[1:34:00] Dr. Lex Fridman: Yeah. Yeah. Yeah. But, like, I don't I mean, unless you're talking about, like, I don't know how you would have sexual relations with a Roomba.[1:34:07] Andrew Huberman: Well, I wasn't necessarily saying, sexual delight, but,[1:34:10] Dr. Lex Fridman: trust me. I tried. I'm just kidding. That's That's a joke, Internet. Okay.[1:34:14] Dr. Lex Fridman: But I was fascinated in the psychology of how little it took because you mentioned you had a negative relationship with the Roomba a little[1:34:21] Andrew Huberman: Only in well, I'd Find that mostly, I took it for granted. Yeah. It just served me. It collected Costello's hair. And then when it would do something I didn't like, I would get upset with it.[1:34:30] Andrew Huberman: So that's not a good relationship.[1:34:41] Dr. Lex Fridman: To frame its, it being quite dumb as, almost cute. You know? You're almost connecting with it for its dumbness, And I think that's a artificial intelligence problem. Interesting. I think flaws are should be a a feature, Not a bug.[1:34:59] Andrew Huberman: So along the lines of this, the different sorts of relationships that one could have with robots and the fear, but also the some of the positive relationships that one could have, there's so much dimensionality. There's so much to explore. But, power dynamics in relationships are very interesting because The the obvious ones that, the unsophisticated view of this is, you know, 1, there's a master and a servant. Right? But there's also manipulation.[1:35:27] Andrew Huberman: There's benevolent manipulation. You know? Children do this with parents. Puppies do this. Puppies turn their head and look cute and maybe give out a little little, noise.[1:35:37] Andrew Huberman: Kids, coo. And parents always think that they're, You know, they're doing this because, you know, they they love the parent, but in many ways, studies show that those coups are ways to the sorts of behaviors and expressions from the parent that they want. The child doesn't know it's doing this. It's completely subconscious, but it's benevolent manipulation. So there's one version of fear of robots that I hear a lot about that I think most people can relate to where the robots take over And they become the masters, and we become the servants.[1:36:08] Andrew Huberman: But there could be another version that, You know, in certain communities that I'm certainly not a part of, but they call topping from the bottom, where the robot is actually manipulating You into doing things, but it you are under the belief that you are in charge, but, actually, They're in charge. And so I think that's one that, if we could explore that for a second, you could imagine it wouldn't necessarily be bad, although it it could lead to bad things. The reason I wanna explore this is I think people always default to the the extreme. Like, The robots take over, and we're in little jail cells, and they're out having fun and and ruling the universe. What what what sorts of manipulation can a robot Potentially carry out, good or bad.[1:36:56] Andrew Huberman: Yeah. Just so there's[1:36:57] Dr. Lex Fridman: a lot of good and bad manipulation between humans. Right? Just like you said. To me, especially, like you said, topping from the bottom. Is that the term?[1:37:11] Dr. Lex Fridman: So[1:37:12] Andrew Huberman: I think someone from MIT told me turn[1:37:14] Dr. Lex Fridman: to you.[1:37:15] Andrew Huberman: Wasn't Lex.[1:37:17] Dr. Lex Fridman: I think so first of all, there's power dynamics, in bed and power dynamics, in relationships and power dynamics, on the street, and in the work environment, those are all very different. I think I think power dynamics can make human relationships, especially romantic relationships, Fascinating and rich and fulfilling and exciting and all those kinds of things, so I don't I don't think In themselves, they're bad. And the same goes with robots. I really love the idea that a robot would be a top or a bottom in terms of, like, power dynamics, and I think everybody should be aware of that. And the manipulation is not so much manipulation, but, a dance of, like, pulling away, push and pull, and all those kinds of things.[1:38:08] Dr. Lex Fridman: In terms of control, I I think we're very, very, very far away from AI systems, they're able to lock us up. They, do lock us up in a in a you know? Like, to have so much control that we basically cannot live our lives in the way that we want. I think there's, in terms of dangers of AI Systems, there's much more dangers that have to do with autonomous weapon systems and all those kinds of things. So the power dynamics as exercised In the struggle between nations and war and all those kinds of things.[1:38:40] Dr. Lex Fridman: But in terms of personal relationships, I think power dynamics are a beautiful thing. Now there's, of course, going to be all those kinds of, discussions about, consent and rights and all those Well,[1:38:53] Andrew Huberman: here we're talking of I always say, you know, in any discussion around this, if if we need to define, really the context, it's always it always should be Consensual, age appropriate, context appropriate, species appropriate. Yeah. But now we're talking about human robot interactions. And so, I guess that no.[1:39:11] Dr. Lex Fridman: I I would actually was trying to make a different point, which is I do believe that robots will have rights down the line. And I think In order for in order for us to have deep meaningful relationship with robots, we would have to consider them as entities in themselves that, deserve respect. And that's a really interesting concept that, I think people are starting to talk about a little bit more, But it's very difficult for us to understand how entities that are other than human I mean, the same as with dogs and, other animals can have rights on a level as humans.[1:39:44] Andrew Huberman: Well, the yeah. I mean, the we we can't and nor should we do whatever we want with animals. We have a USDA. We do we have departments of Agriculture that deal with, you know, animal care and use committees for research, for agri you know, for farming and ranching and all that. So I I While it when you first said it, I thought, wait.[1:40:05] Andrew Huberman: Why would have there'd be a bill of robotic rights? But it absolutely makes sense, in the context of everything We've been talking about up until now. It let's, if you're willing, I'd love to talk about dogs because You've mentioned dogs a couple times, a robot dog. You had a a biological dog. Yeah.[1:40:26] Dr. Lex Fridman: Yeah. I had a a Newfoundland, named Homer, for many years growing up.[1:40:34] Andrew Huberman: In Russia or in the US?[1:40:35] Dr. Lex Fridman: In the United States. And, he was about he's over 200. That's a big dog.[1:40:40] Andrew Huberman: That's a big dog.[1:40:41] Dr. Lex Fridman: If people know people know Newfoundland, so he's this black dog that's, really, long hair and just a a kind soul. I think perhaps that's true for a lot of large dogs, but he thought he was a small dog, he moved like that and[1:40:56] Andrew Huberman: Was he your dog?[1:40:57] Dr. Lex Fridman: Yeah. Yeah.[1:40:58] Andrew Huberman: So you had him since he was fairly young?[1:41:00] Dr. Lex Fridman: Since, yeah, since the very, very beginning till the very, very end. And One of the things I mean, he had this kind of, we mentioned, like, the Roombas. He had a Kindhearted dumbness about him, that was just overwhelming. It's part of the reason, I named him Homer because It's after Homer Simpson, in case people are wondering which Homer I'm referring to. I'm not you know?[1:41:27] Dr. Lex Fridman: So the there's A clodesty. That's yeah. Yeah. Exactly. There's a clumsiness that was just, something that immediately led to a deep love for each other.[1:41:38] Dr. Lex Fridman: And one of the, I mean, he was always it's the shared moments. He was always there for so many, nights together. That's a that's a powerful thing about a dog that, He was there through all the loneliness, through all the tough times, through the successes, and all those kinds of things. And I remember I mean, that was a really moving moment for me. I still miss him[1:42:00] Andrew Huberman: to this day. How long ago did he die?[1:42:05] Dr. Lex Fridman: Maybe 15 years ago. So it's it's been a while. But it was the first time I've really experienced, like, the feeling of death. Is so what happened is, he, he got cancer, And so he's dying slowly, and then at a certain point, he couldn't get up anymore. There's a lot of things I could say here, you know, the that I struggle with that maybe, maybe he suffered much longer than he needed to.[1:42:39] Dr. Lex Fridman: That's something I really think about a lot. But I remember when I had to take him to the hospital, and The nurses couldn't carry him. Right? So you talk about a 200 pound dog, and I was really into power lifting at the time. I remember, Like, they they they tried to figure out all these kinds of ways to, so in order to put them to sleep, they had to take them into into a room, and so I had to carry him everywhere.[1:43:09] Dr. Lex Fridman: And here's this dying friend of mine that I just had to, first of all, it's really difficult to carry, somebody that heavy when they're not helping you out. And, yeah, so I remember it was the 1st time seeing a friend laying there and seeing wife Drained from his body. And that realization that we're here for a short time was made so real That he has a friend that was there for me the week before, the day before, and now he's gone. And that was, I don't know. It that that spoke to the fact that you could be deeply connected with the dog.[1:43:54] Dr. Lex Fridman: Also Spoke to the fact that, the the shared moments together that led to that deep friendship is Are what make life so amazing, but it also spoke to the fact that death is a motherfucker. So I know you've lost Costello recently. Yeah. And you've been going[1:44:16] Andrew Huberman: And as you're saying this, I'm definitely fighting back, the tears. I I, thank you for sharing that that, I guess we're about to both cry over our our dead dogs. That it was that it was bound to happen just given when this is when this is happening.[1:44:33] Dr. Lex Fridman: Yeah. It's, how long how long did you know that Castello was not doing well?[1:44:39] Andrew Huberman: Well, let's see. A year ago, during the start of about 6 months into the pandemic, I he started getting And he was not his behavior changed and something really changed. And then, I put him on testosterone Because, which helped a lot of things. It certainly didn't cure everything, but it helped a lot of things he was dealing with joint pain, sleep issues. And then it just became a a very slow decline to the point where, you know, 2, 3 weeks ago, he had, you know, a Closet full of medication.[1:45:15] Andrew Huberman: I mean, this dog was, you know, it was like a pharmacy. It's amazing to me when I looked at it the other day. Still haven't cleaned up and removed all his things because I can't Quite bring myself to do it, but, do you think he was suffering? Well, so what happened was about a week ago it was really just about a week ago. It's amazing.[1:45:32] Andrew Huberman: He was going up the stairs, and I saw him slip. And he was a big dog. He wasn't 200 pounds, but he was about 90 pounds. But he's a bulldog. He's pretty big, and he was fit.[1:45:41] Andrew Huberman: And then I noticed that he wasn't carrying the a foot in the back like it was injured. It had no feeling at all. He never liked me to touch his high and pause, And I could do that thing was just flopping there. And then, the vet found some spinal degeneration, and I was told that the next one would go. Did he suffer?[1:45:57] Andrew Huberman: Sure hope not. But something changed in his eyes.[1:46:01] Dr. Lex Fridman: Yeah.[1:46:01] Andrew Huberman: Yeah. It's the eyes again. I know you and I spend Long hours on the phone and talking about, like, the eyes and how what they convey and what they mean about internal states and for sake of robots and biology of other kinds. But[1:46:12] Dr. Lex Fridman: Do you think, something about him was gone in his eyes? I[1:46:18] Andrew Huberman: I think he was real here I am anthropomorphizing. I think he was realizing that one of his great joys in life, which was to walk and sniff and pee on things.[1:46:33] Dr. Lex Fridman: This dog The fundamentals. Loved[1:46:35] Andrew Huberman: to pee on things. It was amazing. I wondered where he put it. He was like a reservoir of urine. It was incredible.[1:46:42] Andrew Huberman: I think, oh, that's it. He's just he put, like, 1 drop on the 50 millionth plant, and then we get to the 50 millionth in one land, and he just have, you know, leave a puddle. And here I am talking about Costello ping. He was losing that ability to stand up and do that. He was Falling down while he was doing that.[1:46:58] Andrew Huberman: And I I do think he started to realize, and the the passage was easy and peaceful, but, You know, I'll say this. I I'm not ashamed to say it. I mean, I wake up every morning since then just I I don't even make the conscious Decision to allow myself to cry. Wake up crying. And, I'm fortunately able to make it through the day thanks to the great support of my friends and and you and my family, but, I miss him, man.[1:47:24] Dr. Lex Fridman: You miss him?[1:47:24] Andrew Huberman: Yeah. I miss him. And I feel like, he you know, Homer, Costello you know, the relationship to one's dog is so Specific. But,[1:47:34] Dr. Lex Fridman: so that that party is gone. That's the hard thing. You know,[1:47:44] Andrew Huberman: What's what what I think is different is that I made the mistake, I think. I hope it was a good decision, but sometimes I think I made the mistake of I brought Costello a little bit to the world through the podcast, through posting about him. I gave I answered for more advised about him in public. Let's be honest. I have no idea what his mental life was or his relationship to me.[1:48:04] Andrew Huberman: And I'm just exploring all this for[1:48:12] Dr. Lex Fridman: the episode, you released on Monday. You mentioned Costello. Like, you you brought him back to life for me for that brief moment.[1:48:20] Andrew Huberman: Yeah. But he's he's he's gone.[1:48:22] Dr. Lex Fridman: Well, that's the he's gonna be gone for a lot of people too.[1:48:28] Andrew Huberman: Well, this is what I'm struggling with. I think that maybe You're pretty good at this, Lola. Wait. Have you done this before? This is the challenge is I actually part of me I know how to take care of myself Pretty well.[1:48:42] Andrew Huberman: Yeah. Not perfectly, but pretty well. And I have good support. I I do worry a little bit about how it's gonna land and how people will feel. I'm I'm concerned about Their internalization.[1:48:53] Andrew Huberman: So that's something I'm still I'm still iterating on.[1:48:56] Dr. Lex Fridman: And you have to we have to watch you struggle, which is That's a Right.[1:48:59] Andrew Huberman: And I've mostly been shielding them from this, but, what would make me happiest if is if people would internalize some of Costello's best traits and his best traits were that he was incredibly tough. I mean, he was a, You know, 22 inch neck, bulldog, the whole thing. He was just born that way. But was what was so beautiful is that his toughness is never what he Rolled forward, it was just how sweet and kind he was. And so if people can take that, then, then there's a win in there someplace.[1:49:32] Dr. Lex Fridman: So I I think there's some ways in which you should probably live on in your podcast too. You should, I mean, it's such a one of the things I loved about, his role in your podcast is that he brought so much joy to you. We mentioned the robots. Mhmm. Right?[1:49:51] Dr. Lex Fridman: I think, that's such a powerful thing to bring that joy into like, Allowing yourself to experience that joy, to bring that joy to others, to share it with others, that's really powerful. And, I mean, Not to this is this is, like, the Russian thing is, it's I it touched me when, Louis CK had that moment That I keep thinking about in this, his show Louie, where, like, an old man was criticizing Louie for whining about breaking up with his girlfriend, And you're saying, like, the most, the the most beautiful thing, about love. They made a song that's Catch you now that's not making me feel horrible saying it, but, like, it's the loss. The loss really also is Making you realize how much that person, that dog meant to you and, like, Allowing yourself to feel that loss and not run away from that loss is really powerful. And in some ways, that's also sweet.[1:50:55] Dr. Lex Fridman: Just like the love was, the loss is also sweet because you know that you felt a lot for that, for your friend. So I you know? And, like, continue to bring that joy. I think it would be amazing to the podcast. I hope to do the same with With robots or whatever else is the source of joy.[1:51:15] Dr. Lex Fridman: Right? And maybe, do you think about one day getting, another dog?[1:51:22] Andrew Huberman: Yeah. In time. You're hitting on all the key buttons here. I want that to We're thinking about, you know, ways to kind of immortalize Costello in a way that's real, not just, you know, creating some little logo or something silly. Know, Costello, much like David Goggins, is a a person, but it Goggins also has grown into kind of a verb.[1:51:47] Andrew Huberman: You're gonna Goggins this or you're gonna and there's an adjective. Like, that's extreme like it. I think that for me, Costello was all those things. He was a he was a being. He was his own being.[1:51:56] Andrew Huberman: He was a noun, a verb, and an adjective. So and he had this amazing superpower that I wish I could get, which is this ability to get everyone else to do things for you without doing A damn thing. The Costello effect as I call it.[1:52:10] Dr. Lex Fridman: So it's an idea. I hope he lives on.[1:52:12] Andrew Huberman: Yes. Thank you for that. This actually has been very therapeutic for me, for me, which which actually brings me to a question. We're friends. We're not just Co scientist colleagues working on a project together and, and in the world, that's Somewhat similar.[1:52:34] Dr. Lex Fridman: Just just 2 2 dogs.[1:52:37] Andrew Huberman: Just 2 dogs, basically. But Let's talk about friendship, because I think that, I certainly know as a scientist, That there are elements that are very lonely of the scientific pursuit. There are elements, of many pursuits that are lonely. Music, Math always seemed to me like they're, like, the loneliest people. Who knows if that's true or not?[1:53:04] Andrew Huberman: Also, people work in teams and sometimes people are surrounded by people interacting with people, and they feel very lonely. But for me and I and I think As well for you, friendship is an incredibly strong force in making One feel like certain things are possible or worth reaching for. Maybe even making us compulsively reach for them. So When you were growing up, you grew up in Russia until what age? 13.[1:53:33] Andrew Huberman: K. And then and then you moved directly to Philadelphia?[1:53:38] Dr. Lex Fridman: To Chicago. Chicago. And then Philadelphia, you know, and then San Francisco and Boston and so on. But, really, To Chicago. That's where I went to high school.[1:53:48] Andrew Huberman: Do you have siblings?[1:53:49] Dr. Lex Fridman: Brother older brother.[1:53:50] Andrew Huberman: But most people don't know that.[1:53:53] Dr. Lex Fridman: Yeah. He, is a very different Very different person, but somebody I definitely look up to. So he's a wild man. He's extrovert. He's, He was into, I mean so he's a he's also a scientist, a bioengineer, but he's when we were growing up, and he was, The person who, you know, did, drank and did every drug and but also is the life of the party, and And I just thought he was the you know, when you're the older brother, 5 years older, he was the coolest person, that you know, I I always wanted to be him.[1:54:28] Dr. Lex Fridman: So So that he was he definitely had a big influence. But I think for me, in terms of friendship growing up, I had, I had one really close friend. And then when I came here, I had another close friend. But I'm very, I believe, I don't know if I believe, but I draw a lot of strength from deep connections With, with other people and just a small number of people, just a really small number of people. That's when I moved to this country.[1:55:00] Dr. Lex Fridman: I was really surprised How, like, there are these these, large groups of friends, quote, unquote, but they The the the the depth of connection was not there at all from my sort of perspective. Now I I moved to the suburb of Chicago. It was Naperville. It's more like a middle class, maybe upper middle class. So it's like people that, cared more about material possessions than deep human connection.[1:55:26] Dr. Lex Fridman: So that added to the thing, but I I drove more meaning than almost anything else was friendship early on, I had a best friend. His name was his name is. I don't know how to say it in English. How do you[1:55:43] Andrew Huberman: say it in Russian? Yura. What is it last name? Do you remember if it's[1:55:48] Dr. Lex Fridman: Myrkullov. Yura Myrkullov. So we just spend all our time together. There's there's a there's also a group of friends. Like Mhmm.[1:55:59] Dr. Lex Fridman: I don't know. It's, like, 8 guys. In Russia, growing up, it's, like, parents didn't care if you're coming back at a certain hour, so we spend all day, All night just playing soccer, usually, called football, and just talking about life and all those kinds of things. Even at the young age, The I think people in Russia and Soviet Union grow up much quicker. I think the education System at the university level is world class in the United States in terms of, like, really creating really, big powerful minds, At least it used to be, but I think that they aspire to that.[1:56:42] Dr. Lex Fridman: But the education system for, like, for younger kids In Soviet Union was incredible. Like, they did not treat us as kids. We the the level of literature, Tolstoy Dostoevsky[1:56:54] Andrew Huberman: you were just small child?[1:56:56] Dr. Lex Fridman: Yeah. That's just you're amazing. And, like, the level of mathematics, and you're made to feel like shit if you're not good at mathematics. Like, we I think in this country, there's more like, especially young kids because they're so cute. Like, they're being babied.[1:57:12] Dr. Lex Fridman: We only start to really push adults later in life. Like so if you wanna be the best in the world at this, then you get to be pushed. But we were pushed at a young age. Everybody was pushed, and that brought out the best in people. I think, they really forced people to discover, Like, discover themselves in the Goggin style, but also discover, what they're actually passionate about, what they're not.[1:57:35] Andrew Huberman: Is this true for boys and girls? Were they pushed equally there?[1:57:39] Dr. Lex Fridman: Yeah. They were pushed, yeah, they were pushed equally, I would say. There was, obviously, there was more not obviously, but There at least from my memories, more of, what's the right way to put it? But there was, like, gender roles, Mhmm. But not in a negative connotation.[1:57:56] Dr. Lex Fridman: It was it was the red dress versus the suit and tie kind of connotation, which is like There's, you know, like, guys like lifting heavy things, and girls like creating beautiful Art and, you know, like so there's[1:58:14] Andrew Huberman: A more traditional view of Yeah. General more, 19 fifties, sixties.[1:58:18] Dr. Lex Fridman: But we didn't think in terms of, at least at that age, In terms of, like, roles and then, like, homemaker or something like that or no. It was more about what people care about. Like, girls cared about This set of things and guys cared about this set of things. I think mathematics and engineering was something that guys cared about in sort of At least my perception of that time. And then girls create about girls cared about beauty.[1:58:43] Dr. Lex Fridman: So, like, guys wanna create machines. Girls wanna create beautiful And now, of course, that I don't take that forward in some kind of philosophy of life, but it's just the way I grew up and the way I remember it. But all, everyone worked hard. The the value of hard work was, instilled in everybody. And, through that, I I think it's it's, like, a little bit of hardship.[1:59:12] Dr. Lex Fridman: Of course, also economically, everybody was poor, especially with the collapse The Soviet Union, there's poverty everywhere. You didn't notice it as much, but there was a because there's not much material possessions, There was a huge value placed on human connection. Just, meeting with neighbors, everybody knew each other. We lived in an apartment building very different than you have in the United States these days. Everybody knew each other.[1:59:38] Dr. Lex Fridman: You know, you would get together, drink vodka, smoke Cigarettes and play guitar and sing, sad songs about, about life.[1:59:47] Andrew Huberman: What's it what's with the the Sad songs and the Russian thing. I mean, I I Russians do express joy from time to time. They do. Certainly, you do. But, what do you think that's about?[2:00:00] Andrew Huberman: Is it because it's cold there? But it's cold other places too. Right.[2:00:04] Dr. Lex Fridman: I think, this is so first of all, The Soviet Union, the echoes of World War 2 and the millions and millions and millions of people that civilians that were slaughtered And, also, starvation is there. Right? So, like, the echoes of that of the ideas, the literature, the art is there. Like, that's Grandparents, it's parents. That's all there.[2:00:29] Dr. Lex Fridman: So that contributes to it, that life can be absurdly, unexplainably cruel. At any moment, everything can change. So that's in there. Then I think there's an empowering aspect to finding beauty and suffering But then everything else is beautiful too. Like, if you just linger or it's like why you meditate on death, it's like if you just Think about the worst possible case and find beauty in that, then everything else is beautiful too.[2:00:54] Dr. Lex Fridman: And so you write songs about the dark stuff. And, that somehow helps you deal with whatever comes. There there's a hopelessness to The the Soviet Union that, like, you know, inflation, all those kinds of things were people were sold dreams and never delivered. And so, like, there's a there's a if you don't sing songs about sad things, you're going to become cynical Nicole bought this world.[2:01:24] Andrew Huberman: Interesting.[2:01:24] Dr. Lex Fridman: So they don't wanna give in to cynicism. Now a lot of people did. You know, one of the But that it's the battle against cynicism. One of the, things that may be common in Russia is a kind of cynicism about, Like, if I told you the thing I said earlier about dreaming about robots, it's very common for people to, dismiss that dream I'm saying, no. That's not that's too wild.[2:01:52] Dr. Lex Fridman: Like, who else do you know that did that? Or you wanna start a podcast? Like, who else? Like, nobody's making money on podcasts. Like, why do you wanna start a podcast?[2:02:00] Dr. Lex Fridman: That kind of mindset, I think, is quite common, which is why I would say Entrepreneurship in Russia is still not very good, which to be a business like, to be an entrepreneur, you have to dream big, you have to have others around you like friends and support group that makes you make you dream big. But if you don't give into cynicism And appreciate the beauty in, the the unfairness of life, the absurd unfairness of life, then I think it just makes, makes you appreciative of everything. It's like a it's a prerequisite for gratitude. And so, Yeah. The I think that instilled in me ability to appreciate everything.[2:02:43] Dr. Lex Fridman: Just like everything everything's amazing. And then also, there's a culture, of of, like, romanticizing everything. Like, It's almost like, like, romantic relationships worth were very, like, soap opera alike. It's very, like, over the top dramatic, and I think I think that that was instilled in me too. Not only do I appreciate everything about life, But I get, like, emotional about it.[2:03:15] Dr. Lex Fridman: In a sense, like, I get, like, a visceral feeling of joy For everything. And the same with, you know, friends or people of the opposite sex. Like, there's a deep, like, Emotional connection there that, like that's, like, way too dramatic to like, I guess, relative to what the actual moment is. But I I I derive so much deep, like, dramatic joy From so many things in life, and I think I would attribute that to the upbringing in Russia. But the thing that sticks most of all is, the friendship.[2:03:53] Dr. Lex Fridman: And I've Now since then, had, one other friend like that in, in the United States. He lives in Chicago. His name is Matt. And slowly, here and there, accumulating really fascinating people, but I'm very selective with that. Funny enough, the few times you know, it's not few.[2:04:16] Dr. Lex Fridman: It's a lot of times now interacting with Joe Rogan. It Sounds surreal to say, but there was a kindred spirit there. Like, I've connected with him. And there's been people like that also in the grappling sports that I really connected with. I've actually struggled, which is why I'm so I'm so glad to be your friend, is I've struggled to connect with Scientists.[2:04:40] Dr. Lex Fridman: Like, they can be a[2:04:40] Andrew Huberman: little bit wooden sometimes. Yeah. Even the biologists. I mean, one thing that I He he's up to Well, I'm so struck by the fact that you, you know, you work with robots. You're an engineer, AI, you know, science technology, and That all sounds like hardware.[2:04:55] Andrew Huberman: Right? But what you're describing, and I know is true about you, is this deep emotional life and this Resonance, and it's it's really wonderful. I actually think it's one of the reasons why so many people, scientists and otherwise, have gravitated towards you and your podcast is because You hold both elements. You know, in Hermann Hess's book I don't know if you're at Narcissus and Goldman. Right?[2:05:16] Andrew Huberman: It's about these elements of the logical rational mind and the The the emotional mind and how those are woven together. And if people haven't read it, they should. And, you embody the the full picture, I think that's so much of what draws people to you.[2:05:29] Dr. Lex Fridman: I've read every Herman Hesse book[2:05:31] Andrew Huberman: by the way. As usual as usual, I've done about 9% of of what life is no. It's True. You you mentioned Joe, who is a a phenomenal human being, not just for his amazing accomplishments, but for how he Shows up to the world 1 on 1. I think I heard him say the other day on an interview, he Said, there is no public or private version of him.[2:05:55] Andrew Huberman: He's like, this is this is me. He said the word it was beautiful. He said, I'm like the fish that got Through the net. You know? There is no on stage, off stage version.[2:06:03] Andrew Huberman: You're absolutely right. And I so but well, you guys Good. I have a question about[2:06:09] Dr. Lex Fridman: But that's a really good point about public and private life. He was a huge if I could just comment real quick. Like that, he was, I've been a fan of Joe for a long time, but he's been inspiration to, to not have any difference between public and private life. I actually had a conversation with Naval about this, And he said that you can't have a rich life, like, exciting life If you're the same person publicly and privately. And, I think I understand that idea, but I don't agree with it.[2:06:45] Dr. Lex Fridman: I I think it's really fulfilling and exciting to be the same person privately and publicly with very few exceptions. Now that Dead, I don't have any really strange sex kinks. So, like, I feel I can be open with basically everything. I don't have anything I'm ashamed of. You know, there's some things that could be perceived poorly like the screaming Roombas, but I'm not ashamed of them.[2:07:09] Dr. Lex Fridman: I just have to Present them in the right context, but there is, there's freedom to be in the same person in private as in public. And that, Joe, made me realize that, Yeah. You can you can be that and also to be kind to others. It sounds It sounds kind of absurd, but I really I really always enjoyed, like, Being good to others. Like, just being kind towards others.[2:07:41] Dr. Lex Fridman: But I always, felt like the world didn't want me to be. Like, there's so much negativity when I was growing up, like, just around people. If you actually just notice how people talk, they, from, like, complaining about the weather. This could be just like the big cities that I've But there's a general negativity, and positivity is kind of, suppressed. You're not 1, you're not seen as, as very intelligent, And 2, there's a kinda you're seen as, like, a little bit of a weirdo.[2:08:13] Dr. Lex Fridman: And so I always felt like I had to hide that. What Joe made me realize, 1, I have I can be fully just the same person, private and public, and, 2, I can embrace being kind And just in the way that I like, in the way I I know how to do and sort of, for me, on, like, on Twitter, or, like, publicly, whenever I say stuff, that means saying stuff simply almost to the point of cliche. And, like, I have the strength now To say it even if I'm being mocked. You know what I mean? Like, just it's okay.[2:08:48] Dr. Lex Fridman: It everything's going to be okay. Okay? Some people will think you're dumb. They're probably right. The point is, like, just enjoy being yourself.[2:08:56] Dr. Lex Fridman: And that Joe Joe, more than almost anybody else, because he's so successful, at it, inspired me to do that. Be and be the same person private and public.[2:09:06] Andrew Huberman: I love it. And I I love the idea that authenticity doesn't have to be oversharing. Right? That it doesn't mean you reveal every detail of your life, what you know, it it's a way of being true to an essence of oneself.[2:09:18] Dr. Lex Fridman: Right. You're not there's never a feeling when you deeply think and introspect that you're hiding something from the world or you're being dishonest in some fundamental way. So, yeah, is it that that, that's truly liberating. It allows you to think. It allows you to, like, Think freely, to speak freely, to just to be freely.[2:09:42] Dr. Lex Fridman: That said, it's not like, you know, It's not like there's not still a responsibility to be the best version of yourself. So, you know, I'm very careful With the way I say something. So the whole point, it's it's not so simple to, express the spirit that's inside you with words. It it depend I mean, some people are much better than than others. I struggle.[2:10:09] Dr. Lex Fridman: Like, oftentimes, when I Say something, and I hear myself say it. It sounds really dumb and not at all what I meant. So that's the responsibility you have. It's not just, like, being the same person publicly and privately means you can just say whatever the hell. It means, there's still a responsibility to try to be to express who you truly are, And that that's that's, that's hard.[2:10:32] Andrew Huberman: It is hard. And I think that, you know, so we have this, Pressure, all people when I say we, I mean all all humans and maybe robots too, feel this pressure to be able to express ourselves in that one moment, in that one form. And it is beautiful when somebody, for instance, can capture some essence of love or Badness or anger or something in a song or in a poem or in a short quote. But perhaps it's also possible to do it in aggregate. You know?[2:11:03] Andrew Huberman: All all the things. You know? How you show up. You're for instance, one of the things that initially drew me to want to get to know you as a human being and a scientist and eventually we became friends was the level of respect that you brought to your podcast listeners by wearing a[2:11:19] Dr. Lex Fridman: Suit. Yeah.[2:11:19] Andrew Huberman: I'm being serious here.[2:11:20] Dr. Lex Fridman: You know? I think of it.[2:11:21] Andrew Huberman: I was raised thinking that if you overdress a little bit, overdress by American Mhmm. Certainly, by American standards, you're Overaddressed for a podcast, but this is but it's genuine. You're not doing it for any reason except I have to assume, and I assumed at the time, That it was because you have a respect for your audience. You respect them enough to show up a certain way for them. It's for you also, but it's for them.[2:11:44] Andrew Huberman: Yeah. And I think between that and your commitment to your friendships, the way that you talk about friendships and love and the way you hold up these higher ideals, I think at least as a consumer of your content, and as your friend, I what I find is that in aggregate, You're communicating who you are. It doesn't have to be 1 quote or something. And I think that, you know, we we're sort of obsessed by, like, The one Einstein quote or the one line of of poetry or something, but it's the I think you so embody the way that, And, Joe, as well, it's about how you live your life and how you show up as a collection of things and said and done.[2:12:24] Dr. Lex Fridman: Yeah. That that's fast. And so the aggregate is is the goal. The the the tricky thing and Jordan Peterson talks about this he's under attack way more than you and I will ever be, but that now. For now.[2:12:37] Dr. Lex Fridman: Right? This is very true for now. That, I'll the people who attack on the Internet, this is one of the problems with Twitter, is, they don't consider the aggregate. They they take a single statement. And so one of the defense mechanisms, Again, why Joe has been an inspiration is that when you, in aggregate, are a good person, a lot of people will know that.[2:13:07] Dr. Lex Fridman: And so that makes you much more immune to the attacks of people that bring out an individual statement that might be a misstatement of of some kind or doesn't express, who you are. And so that, I like that idea as the aggregate. And the the the power of the podcast is you have Hundreds of hours out there and being yourself, and people get to know who you are. And once they do and you and you post pictures of Screaming Roombas as you kick them, they will understand that you don't mean well. By the way, as as a side comment, I don't know if I wanna release this because it's It's it's not just the Roombas.[2:13:46] Andrew Huberman: You have a whole dungeon of robots.[2:13:48] Dr. Lex Fridman: Okay. So this is a this is a problem. This the Boston Dynamics came up against this problem, but let let me just let me work this like, workshop this out with you, and maybe Because we'll post this, people will let me know. So there's legged robots. You know?[2:14:07] Dr. Lex Fridman: They look like a dog. They have a very I'm trying to create a very real, human robot connection, but, like, they're also incredible because you can throw them, like, off of a building, and it'll land fine. And it's beautiful.[2:14:22] Andrew Huberman: That's amazing. I've seen the Instagram videos of, like, cats getting jumping off of, like, 5th story billions and then walking away. Yeah. No one should throw their cat out of[2:14:30] Dr. Lex Fridman: Well, this is the problem I'm experiencing. I'll I'll certainly kicking the robots. It's really fascinating how they recover from those kicks. But, like, just seeing myself do it and also seeing others do it, it just does not look good. And I don't know what to do with because I it's such a I'll[2:14:46] Andrew Huberman: do it.[2:14:48] Dr. Lex Fridman: I see. But, you know, I you because you at Robot. No.[2:14:53] Andrew Huberman: I'm kidding. I now now I'm you know what's interesting?[2:14:56] Dr. Lex Fridman: Yeah.[2:14:56] Andrew Huberman: Before today's conversation, I probably could do it. And now I think I'm thinking about robots' bills of rights and things. I'm actually and not not for any not to satisfy you or to satisfy anything except that If I if they have some sentient aspect to their being, then I would loathe to kick[2:15:16] Dr. Lex Fridman: it. I don't think you'll be able to kick it. You might be able to kick it the 1st time, but not the 2nd. This this is the problem I've experienced. One of the cool things is, One of the robots I'm I'm working with, you can pick it up by 1 leg, and it's dangling.[2:15:29] Dr. Lex Fridman: You can throw it in any kind of way, and it'll land correctly.[2:15:33] Andrew Huberman: So is really a friend who had a cat like that.[2:15:37] Dr. Lex Fridman: Oh, man. We look forward to the letters from the cat.[2:15:40] Andrew Huberman: Oh, no. I'm not suggesting anyone did that, but his he had this cat. And the cat, he would just, you know, throw it onto the bed from across the room, and then it would run back for for more somehow. They had that was the nature of the relationship. I think No one should do that to an animal, but this cat seemed to, you know, return for it for whatever reason.[2:15:57] Andrew Huberman: The robot is[2:15:58] Dr. Lex Fridman: a robot, and it's fascinating to me how hard it is for me to do that. So it's unfortunate, but I don't think I can do that to a robot. Like, it I I struggle with that. I So for me to be able to do that with a robot, I have to almost get, like, into the state that I imagine, like, doctors get into when they're doing surgery. Like, I have to start I have to do what robotics colleagues of mine do, which is, like, start seeing it as an object Associate.[2:16:25] Dr. Lex Fridman: Like, dissociate. So which is fascinating that I have to do that in order to do that with a robot. I just want to, take that little bit of a tangent.[2:16:33] Andrew Huberman: No. I think it's an important thing. I mean, I am not, I'm not shy about the fact that for many years, I've I've worked on experimental animals, and that's been a very challenging aspect to being a biologist, mostly mice, but in the past, no longer, thank goodness, because I just don't like doing it. Larger animals as well. And now I work on humans, which I can give consent verbal consent.[2:16:56] Andrew Huberman: So, I think that it's Extremely important to have an understanding of what the guidelines are and where one's own boundaries are around this. It's it's, It's not just an important question. It might be the most important question before any work can progress.[2:17:12] Dr. Lex Fridman: So you, you asked me about friendship. I know you have A lot of thoughts about friendship. What do you think is the value of friendship in life?[2:17:22] Andrew Huberman: Well, for me, personally, just because of My life my life trajectory and arc, friendship, and I should say, I do have some, Female friends that are just friends, they're completely platonic relationships, but it's been mostly male friendship to me has been It's[2:17:39] Dr. Lex Fridman: been all male friendships to me, actually.[2:17:42] Andrew Huberman: Yeah. It's been a, an absolute lifeline. They are my family. I have a biological family, and I have great respect and love for them and appreciation for them, but It it provide it's provided me, the I wouldn't even say confidence because there's always an anxiety in taking Any good risk Mhmm.[2:18:02] Dr. Lex Fridman: Or[2:18:02] Andrew Huberman: any risk worth taking, it's given me the, sense that I should Go for certain things and try certain things to take risks to to weather that anxiety. And I I don't, consider myself a particularly competitive person, but I would sooner die than disappoint or let down one of my friends. I I can think of nothing worse actually than disappointing one of my my friends. Everything else is secondary to me.[2:18:31] Dr. Lex Fridman: What disappointment?[2:18:33] Andrew Huberman: Disappointing meaning, Not I mean, certainly, I strive always to show up as best I can for the friendship, and that can be in small ways. That can mean, you know, making sure the phone is away. Sometimes it's about you know, I'm terrible with punctuality because I'm an academic, and so I just get lost in time, and I don't mean anything by it. But you're striving to to listen, to to enjoy good times, to and to make time. You know?[2:18:58] Andrew Huberman: It kinda goes back to this 1st variable we talked about to make sure that I spend time and to get time in person and check-in, and, it's I think there's so many ways in which friendship is vital to me. It's it's actually, to me, what makes life worth living. Yeah.[2:19:15] Dr. Lex Fridman: Well, there's, I am surprised, like, with the high school friends how we don't actually talk that often these days in terms of time. But every time we see each other, it's immediately right back to where we started. So I, you know, I struggle with that how much time you really allocate for the for the friendship to be deeply meaningful because they're just they're always there with me Even if we don't talk often. So there's a kind of loyalty. I I think, maybe it's a different style, but I think, much, To me, friendship is being there in the hard times, I think.[2:19:51] Dr. Lex Fridman: Like, I I'm much more reliable When you're going through shit, then then, like You're pretty reliable anyway. No. But if, like, you're if you're, like, like, a wedding or something like that or, like, I don't know. Like, you want an award of some kind. Like, yeah.[2:20:09] Dr. Lex Fridman: The I'll congratulate the the the shit out of you, but, like, that's not And I'll be there, but that's not as important to me as being there when, like, nobody else is. Like, just being there when shit gets, shit hits the fan or Something is tough where the world turns their, back on you, all those kinds of things. That to me that's where friendship is meaningful.[2:20:29] Andrew Huberman: Well, I know that To be true about you, and that's a felt thing and a real thing with you. Let me ask one more thing about that actually because I'm not a practitioner of jiu jitsu. I know you are, Joe is. But, years ago, I read a book that I really enjoyed, which is Sam Sheridan's book, A Fighter's Heart. He talks about all these different forms of martial arts and, and Maybe it was in the book.[2:20:49] Andrew Huberman: Maybe it was in an interview, but he said that, you know, fighting or being in physical battle with somebody, jujitsu, boxing, Or some other form of physical direct physical contact between 2 individuals creates this bond unlike any other Because he said it's it's like a 1 night stand. You're sharing bodily fluids with somebody that you barely know.[2:21:09] Dr. Lex Fridman: Yeah.[2:21:10] Andrew Huberman: And I you know, and I chuckled about it because it's it's kinda funny and it kind of tongue in cheek. But at the same time, I think, this is a fundamental way in which, members of a species bond is through physical contact. And, certainly, there are other forms. There's cuddling, and there's hand holding, and there's, and there's sexual intercourse, and[2:21:29] Dr. Lex Fridman: there's all sorts of things. What's cuddling? I haven't heard of it.[2:21:32] Andrew Huberman: Heard this recently. I didn't know this term, but there's a term, they've turned the noun cupcake into a verb. Cupcaking, it turns out. I just learned about this. Cupcaking Caking is when you spend time just cuddling.[2:21:45] Andrew Huberman: I didn't know about this. You heard it here first, although I heard it first just the other day. Cupcaking actually a cuddling[2:21:50] Dr. Lex Fridman: is everything. It's not just like, is it in bed, or is it on the couch? Like, what's cut cuddling? I need to look up what cuddling is.[2:21:56] Andrew Huberman: To look at then we need to define the variables. I think it definitely has to do with physical contact, I I I've been told. But, but in terms of Yeah. Battle, competition, you know, and the Sheridan quote, I'm just curious. So do you Get close or feel, a bond with people that, for instance, you've rolled jiu jitsu with or even though you don't know anything else about Is he was he right about this?[2:22:25] Dr. Lex Fridman: Yeah. I mean, on many levels. He also has the book, A Fighter's Mind.[2:22:29] Andrew Huberman: Yeah. That was the part. One. He's actually an excellent writer. What's interesting about him, just briefly about Sheridan, I don't know him, but I did a little bit of research.[2:22:36] Andrew Huberman: He, he went to Harvard.[2:22:38] Dr. Lex Fridman: Mhmm.[2:22:38] Andrew Huberman: He was an art major at Harvard. He claims all he did was smoke cigarettes and and do art. I don't know if his art was any good. Yeah. And, and I think his father was in the SEAL teams.[2:22:48] Andrew Huberman: And then when he got out of Harvard, graduated, he took off around the world learning all the forms of martial arts and was early to the kind of ultimate Fighting's kind of mixed martial arts and things. Great great book.[2:23:00] Dr. Lex Fridman: Yeah. Yeah. It's it's amazing. I I don't know if you remember it, but I read it. And and I remember Thinking there was amazing encapsulation of what makes fighting the, like, the art like, what makes it compelling.[2:23:12] Dr. Lex Fridman: I would say that There's so many ways that jiu jitsu, grappling, wrestling, combat sports in general is, like, one of the most intimate things you could do. I I don't know if I would describe it in terms of bodily liquids and all those kinds of things.[2:23:27] Andrew Huberman: I think it was more or less Joggin, but,[2:23:30] Dr. Lex Fridman: I think, there's a few ways that it does that. So one, because you're so vulnerable. So that the honesty of stepping on the mat and often all of us Have ego thinking we're better than we are at this particular art, and then the honesty of being submitted or being worse than you thought you are and just sitting with that knowledge. That kind of honesty, we don't get to experience it in most of daily life. We can continue living somewhat of an illusion of our conceptions of ourselves because people are not going to, hit us with the reality.[2:24:13] Dr. Lex Fridman: The mat Speaks only the truth. The the reality just hits you, and that vulnerability is the same as, like, the loss of a loved one. It's the loss of a reality that you knew before. You now have to deal with this new reality. And when you're sitting there in that vulnerability And there's these other people that are also sitting in that vulnerability.[2:24:34] Dr. Lex Fridman: You get to really connect like, fuck. Like, I'm not as special as I thought I was, And life is, like, not you know, life is harsher than I thought I was, and we're just sitting there with that reality. Some of us can put words to them, some we can't. So I think that definitely is a thing that leads to intimacy. The the other thing is is the human contact.[2:24:58] Dr. Lex Fridman: There is something about, I mean, like, a big hug. Like, during COVID, very few people hug me, and I hug them. And I always felt good when they did. Like, we're all tested, and especially now we're vaccinated, but there's still people this is true in San Francisco's. And they wanna keep not only 6 feet away, but stay at home and never touch you.[2:25:21] Dr. Lex Fridman: That that was, that loss of basic humanity is the opposite of what I feel in jujitsu where it was like that that contact where you're like, I don't give a shit about whatever rules we're supposed to have in society where you're not you have to keep a distance and all that kind of stuff. Just the hug, like, That the intimacy of a hug that's like a good bear hug and you're, like, just controlling another person. Communicating through just trying to break each other's arms. I don't I don't exactly understand why violence is The such a close neighbor to love, but[2:26:01] Andrew Huberman: it is. Like, well, in, you know, in the hypothalamus, the neurons that control Sexual behavior, but also nonsexual contact are not just nearby the neurons that control aggression and fighting. They are Salt and pepper with those neurons. It's a very interesting and, you know, it almost sounds kinda risque and controversial and stuff. There's I'm not Anthropomorphizing about what this means.[2:26:27] Andrew Huberman: But in the brain, those structures are interdigitated. They They you can't you can't separate them except at a very fine level. And here, you're the way you describe it is the same as a real thing.[2:26:39] Dr. Lex Fridman: I I I do wanna make an interesting comment. Again, these are the things that could be taken out of context, but, you know, I one of the amazing things about jiu jitsu is is both guys and girls Drain it. And I was surprised. So, like, I'm a big fan of yoga pants. You know, at the gym kind of thing.[2:27:00] Dr. Lex Fridman: It reveals the beauty of, of the female form. But the the thing is, like, girls are, you know, dressed in skin tight clothes in jiu jitsu often. And I found myself, like, not at all thinking like that at all with when training with girls.[2:27:14] Andrew Huberman: Well, the context is very nonsexual.[2:27:17] Dr. Lex Fridman: But that that I was surprised to learn that. Like, I when I first started jiu jitsu, I thought, wouldn't that be kinda weird to train with[2:27:23] Andrew Huberman: the opposites, like, In something so intimate, boys and girls, men and women, they they roll jiu jitsu together completely. Interesting.[2:27:31] Dr. Lex Fridman: And the the only times girls kinda Try to stay away from guys. I mean, there's 2 contexts. Of course, there's always going to be creeps in this world so that everyone knows who's you know, who kinda to stay away from. And the other is, like, there's a size disparity. So girls will often try to roll with people a little bit closer weight wise.[2:27:48] Dr. Lex Fridman: But no. They're that's one of the Things that are empowering to women, that that's what they fall in love with when they start doing jiu jitsu is I I can first of all, they gain an awareness and a pride over their body, which is great. And then 2nd, they get especially later on, start submitting big dudes like these, like, bros that come in who are all shredded and, like, muscular, and they get through technique to, exercise dominance over them. And that's a powerful feeling[2:28:17] Andrew Huberman: to be you've seen women force a a larger guy to tap or or even choke him out.[2:28:22] Dr. Lex Fridman: Well, I was, I was deadlifting, 4 oh, boy. I think it's 495. I was really into power lifting when I started jiu jitsu, and I remember being submitted by you know, I thought I walked in Feeling like I'm going to be, if not the greatest fighter ever, at least top 3. And so so as a white belt, you roll in, like, all happy, and then you realize That, as long as you're not applying too much force, that you're having I remember being submitted many times by, like, a 130, a 120 pound girls At the, Balance Studios in Philadelphia had a lot of incredible female jiu jitsu players, and that's really humbling too. The technique, can overpower in in combat, pure strength.[2:29:12] Dr. Lex Fridman: That that's the other thing There is something about combat that's primal. Like, there it just feels It feels like, we were born to do this. Like, that there's[2:29:27] Andrew Huberman: But we have circuits in our brain that are dedicated to this kind of interaction. There's no there's no question.[2:29:33] Dr. Lex Fridman: And, like, that's what it felt like. It it wasn't that I'm learning a new Skill. It was like, somehow, I am, remembering echoes of something I've learned in the past.[2:29:44] Andrew Huberman: It's like hitting puberty. A child before puberty has no concept of Boys and girls having this, attraction regardless of whether or not they're attracted to boys or girl, doesn't matter. At some point, most people, not all, but certainly, but most people, they hit puberty, suddenly, people appear differently, and certain people take on a a romantic or sexual interest for the very first time.[2:30:07] Dr. Lex Fridman: Yeah.[2:30:07] Andrew Huberman: And so it's like it's revealing a circuitry in the brain. It's not like they learn that. It's innate. And I think it when I hear the way you describe, jiu jitsu and and enrolling jiu jitsu, it reminds me a little bit Joe was telling me, recently about the first time he went hunting, And he felt like it revealed a circuit that was that was in him all along, but he hadn't experienced before.[2:30:30] Dr. Lex Fridman: Yeah. That's that's definitely there. And And, of course, there's the physical activity. One of the interesting things about jiu jitsu is, it's one of the really strenuous exercises that you can do late into your Adult life, like, into your, fifties, sixties, seventies, eighties. I've when I when I came up, there's a few people in their eighties that were training.[2:30:51] Dr. Lex Fridman: And as long as you're smart, as long as you practice techniques and pick your partners correctly, you can do that kind of art that's late into life, and so you're getting exercise. There's not many activities I find that are, amenable to that. So because it's such a thinking game, The the the jujitsu in particular is an art where technique pays off a lot, so you can, still maintain, First of all, remain injury free if you use good technique. And, also, through good technique, Be able to go, you know, be active with people that are much, much younger. And so it that was to me that and running are the 2 activities you can kinda do late in life Because to me, a healthy life is has exercises as the piece of the puzzle.[2:31:39] Andrew Huberman: No. Absolutely. And I'm glad that we're on the physical component because, I know that there's for you, you've talked before about the crossover between the physical and the intellectual and the mental. And, Are you still running at ridiculous hours of the night for ridiculously long[2:31:59] Dr. Lex Fridman: Yeah. So I'm, definitely. I've been running late at night here in Austin. People don't the area we're in now, people say is a dangerous area, which I find laughable coming from the bigger cities. No.[2:32:10] Dr. Lex Fridman: I run late at night. There's something,[2:32:15] Andrew Huberman: if you see a guy running through Austin at 2 AM in a suit and tie, it's Probably.[2:32:22] Dr. Lex Fridman: Well, yeah. I mean, I I do think about that because I get recognized more and more in Austin. I I worry that, But not really. That I get recognized late at night. You know?[2:32:32] Dr. Lex Fridman: But there is something about the night That brings out those deep philosophical thoughts and self reflection that I really enjoy. But recently, I started getting back to the grind, so I'm gonna be competing Are hoping to be compete at, in September October In jiu jitsu. In jiu jitsu, yeah, to get back to competition. And so That requires getting, back into a great cardio shape. I said I've been getting, running as part of my daily routine.[2:33:02] Andrew Huberman: Got it. Yeah. Well, I always know I can reach you regardless of time zone in the middle of the night, wherever that happens.[2:33:09] Dr. Lex Fridman: But part of that has to be just being single and Being a programmer. Those those 2 things just don't work well in terms of a steady sleep schedule.[2:33:18] Andrew Huberman: It's not bankers hours kind of work.[2:33:20] Dr. Lex Fridman: 9 to 5.[2:33:21] Andrew Huberman: I wanna, you mentioned single. I want to ask you a little bit about the other form of relationship, which is, romantic love. So, your parents are still married?[2:33:32] Dr. Lex Fridman: Still married. Still happily married.[2:33:34] Andrew Huberman: That's impressive. Yeah. A rare thing nowadays. Yeah. So you grew up with that example.[2:33:39] Dr. Lex Fridman: Yeah. I guess that's a powerful thing, right, if there's an example that I think can work.[2:33:43] Andrew Huberman: It Yeah. I didn't have that in my own family, but, when you when I see it, it's it's inspiring, and it's and it's beautiful. The fact that they have that And that was the norm for you, I think, is is really wonderful.[2:33:56] Dr. Lex Fridman: It it was, in the case of my parents, it was interesting to watch because there's obviously tension. Like, there'll be times when they fought and all those kinds of things. They, they obviously get frustrated with each other, and they they, like But they find mechanisms how to communicate that to each other, like to make fun of each other a little bit, like to tease, to get some of that frustration out, then ultimately, to reunite and and and to find their joyful moments and be that the energy. I think it's clear because they got together in their, I think, Early twenties, like, very, very young. I think you grow together as people.[2:34:32] Andrew Huberman: Yeah. You're still in the critical period of brain plasticity.[2:34:37] Dr. Lex Fridman: And, also, I mean, it's just like divorce was so frowned upon that you stick it out. And I think a lot of couples, especially from that time, Soviet Union that probably applies to a lot of cultures. You stick it out, and you put in the work. You learn how to put in the work. And once you do, you start to get to some of those Rewarding aspects of being, like, through time, sharing so many moments together.[2:35:01] Dr. Lex Fridman: You know? That, that's definitely something that, that was an inspiration to me, but maybe that's where I have so I have a similar of longing to have a lifelong partner, like, that have that kind of view where, same with friendship, lifelong friendship is the most meaningful kind. That there is something with that time of sharing all that time together, like till death do us part as a powerful thing. Not by force, not because the religion said it or the government said it or your culture said it, but because you want to.[2:35:33] Andrew Huberman: Do you want children?[2:35:34] Dr. Lex Fridman: Definitely. Yeah. Definitely want children. It's it's com How[2:35:39] Andrew Huberman: many Roombas do you have?[2:35:41] Dr. Lex Fridman: Oh, oh, I thought You should No.[2:35:42] Andrew Huberman: No. Human children. No. Human human children.[2:35:44] Dr. Lex Fridman: Because I already have the children.[2:35:45] Andrew Huberman: Exact well, I was saying you probably need at least as many, human children as you do a room with. Big family, small family. So in your mind's eyes, they're a big they're a bunch of bunch of little Freedmans running around.[2:35:59] Dr. Lex Fridman: So I'll tell you, like, Realistically, I I can explain exactly my thinking. And this is similar to the robotics work is if I'm, like, purely logical right now, My answer would be I don't want kids because I just don't have enough time. I have so much going on. But when I'm using the same kind of vision I use for the robots is I know my life will be transformed with the first. Like, I know I would love being a father.[2:36:27] Dr. Lex Fridman: And, so the question of how many I that that's on the other side of that hill. It It could it could be some ridiculous number. So I just know that[2:36:36] Andrew Huberman: I I have a feeling, and I could be I I don't have a crystal ball, but, I don't know. I I see in upwards of of certainly 3 or more come comes to mind.[2:36:47] Dr. Lex Fridman: So so much of that has to do with, the partner you're with too. So, like, that that's such an open question, especially in this society, of what the right partnership is. Because I'm I'm I'm I'm deeply empathetic. I wanna see like, to me, what I look for in a relationship is, For me to be really excited about the passions of another person, like, whatever they're into, it doesn't have to be, career success, any kind of Success, just to be excited for them and for them to be excited for me and, like, sharing that excitement and build and build and build. But there's also practical aspects of, like, what kind of shit do you enjoy doing, together?[2:37:28] Dr. Lex Fridman: And I think family is a real serious undertaking. Oh,[2:37:33] Andrew Huberman: It it certainly is. I mean, I think that I have a a friend, who said it, I think, best, which is that, You first have he's in a very successful relationship and, and has a family, and he said, you first have to define the role, and then you have to cast the right person for The role. Well, yeah, there there[2:37:51] Dr. Lex Fridman: there's some deep aspect to that, but there's also an aspect to which you're not smart enough From this side of it to define the right to to define the role. I think there's part of it that has to be a leap that you have to take. And I I see, I I see having kids that way. You just You just have to go with it and figure it out also as long as there's love there. Like, what the hell is life for even?[2:38:20] Dr. Lex Fridman: So I've I've, there's so many incredibly successful people that I know, that I've gotten to know that all have kids. And the presence of kids, for the most part, has only been something that energized them, Something that gave them meaning, something that made them the best version of themselves, like, made them more productive, not less, which is fascinating to me.[2:38:43] Andrew Huberman: It is fascinating. I mean, you can imagine if the way that you felt about Homer, the way that I feel and felt about Costello is is at all a, A a glimpse of what that must be like then[2:38:54] Dr. Lex Fridman: Exactly. You know? The the downside the thing I worry more about Is, the, the the partner side of that. I've seen, the kids are almost universally a source of increased productivity and joy and happiness. Like, yeah, they're a pain in the ass.[2:39:13] Dr. Lex Fridman: Yeah. It's complicated. Yeah. So so on and so forth. People like to complain about kids.[2:39:18] Dr. Lex Fridman: But when you actually look past that little shallow layer of complaint, kids are great. The source of pain for a lot of people is the if when their relationship doesn't work. And so I'm very kinda concerned about, you know, dating is very difficult, And I'm a complicated person, and so it's it's been very difficult to find to find the right kind of person. But That that statement doesn't even make sense because I'm not on dating apps. I don't see people.[2:39:48] Dr. Lex Fridman: You're like the 1st person I saw in a while. It's like you, Michael Malice, and, like, Joe. So, like, I I don't think I've seen, like, a a a a female, What is it? An element of the female species in quite a in quite a while. So I think you have to put yourself out there.[2:40:06] Dr. Lex Fridman: What is it? Daniel Johnston says true love will find you, but only if you're looking. So there's some element of really taking the leap and putting yourself out there in kinda different situations. And I don't know how to do that when you're behind a computer all the time.[2:40:20] Andrew Huberman: Well, you you're a, you're a builder, and you're a problem solver. And, you're you find solutions, and, I'm confident this solution is, the solution is out there.[2:40:33] Dr. Lex Fridman: And I think you're implying that I'm gonna build the girlfriend, which, I think Or[2:40:38] Andrew Huberman: that you or well and maybe we shouldn't separate this, Friendship, the notion of friendship and community and the if we go back to this concept of the aggregate, you know, maybe you'll meet this woman through, through a Brent. Or maybe or something of that sort.[2:40:53] Dr. Lex Fridman: So one of the things I don't know if you, if you feel the same way. I definitely one of those people that just Falls in love, and that's it.[2:41:02] Andrew Huberman: Yeah. I can't say I'm like that. With with Costello, it was instantaneous. Yeah. It really was.[2:41:07] Andrew Huberman: I mean, I know it's not it's not romantic love, but it's instantaneous. No. I I but that's me. You know? And I think that you if you know, you know, because that that's a That's a good thing that you have that.[2:41:18] Dr. Lex Fridman: Well, it's, I'm very careful with that because you don't wanna fall in love with the wrong person. So I try to be very kinda careful with I I've noticed this because I fall in love with every like, this mug, everything. I fall in love With things in this world. So, like, you have to be really careful because a girl comes up to you and says She loves Dostoevsky. That doesn't necessarily mean you need to marry her tonight.[2:41:46] Dr. Lex Fridman: Exactly.[2:41:46] Andrew Huberman: Yes. And I I like the way you said that out loud so that you heard it. It doesn't mean you need to marry her tonight. Right.[2:41:52] Dr. Lex Fridman: Exactly.[2:41:53] Andrew Huberman: Right.[2:41:53] Dr. Lex Fridman: Exactly. I mean but people people are amazing, and people are beautiful. And that's so I I'm fully embrace that, but I also have to be careful with with relationships. At the same time, like I mentioned to you offline, I I don't There's something about me that appreciates swinging for the fences and not dating, like, doing serial dating or dating around.[2:42:15] Andrew Huberman: Yeah. You're a 1 guy, 1 girl kinda guy. Yeah. You said that.[2:42:18] Dr. Lex Fridman: And it's it's tricky because, you wanna you wanna be careful with that kind of stuff. Especially now, there's a growing platform I have a ridiculous amount of female interest of of a certain kind, but I'm looking for deep connection, and and I'm looking by sitting home alone. And every once in a while, talking to Stanford professors[2:42:41] Andrew Huberman: Perfect solution. Podcast.[2:42:42] Dr. Lex Fridman: Perfect solution. Work out great.[2:42:43] Andrew Huberman: It's it's it's well incorporate it's, part of that constitutes machine learning of sorts.[2:42:49] Dr. Lex Fridman: Yeah. Of sorts.[2:42:51] Andrew Huberman: I would do you mentioned, What has now become a quite extensive and expansive, public platform, which is incredible. I mean, the number of people I don't when I first time I saw your podcast, noticed the suit. I was like, he respects his audience, which was great, but I also thought this is amazing. You know, people are showing up for science and engineering and technology information and those and other sorts of discussions. Now I do wanna talk for a moment about the podcast.[2:43:18] Andrew Huberman: So my 2 questions about the podcast Or when you started it, did you have a plan? And regardless of what that answer is, do you do you know where you're taking it, Or, would you like to leave us, I I do believe in an element of surprise. It's always fun. But what about the podcast? Do you enjoy the podcast?[2:43:37] Andrew Huberman: I mean, your audience Certainly includes me, really enjoys the podcast. It's incredible.[2:43:42] Dr. Lex Fridman: So I love talking to people, and there's something about Microphones that really bring out the best in people. Like, would you you don't get a chance to talk like this. If you and I were just hanging out, we would have a very different conversation In the amount of focus we allocate to each other, we would be having fun talking about other stuff and doing other things. There'd be a lot of distraction. There would be some phone use and all that kind of stuff.[2:44:11] Dr. Lex Fridman: But here, we're 100% focused on each other and focused on the idea. And, like, sometimes playing with ideas that we both don't know, like, the answer to, like a question we don't know the answer to. We're both, like, fumbling with it, trying to figure out trying to get some insights at something we haven't really figured out before and together arriving at that. I think that's magical. I don't know why we need microphones for that, but we somehow do.[2:44:35] Andrew Huberman: Feels like doing science.[2:44:36] Dr. Lex Fridman: It feels like doing science for me, definitely. That's exactly it. Then and I'm really glad you said that because I don't actually often say this, but that's exactly what I felt like. I wanted to talk to friends and colleagues at MIT to do real Science together. That's why how I felt about it.[2:44:57] Dr. Lex Fridman: Like, to to really talk through problems, they're actually interesting As opposed to, like, incremental work that we're currently working for, for a particular conference. Really asking questions like, what are we doing? Like, where is this headed to? Like, what are the big is this really going to help us, solve in in the case of AI, solve intelligence. Like, is this even working on intelligence?[2:45:24] Dr. Lex Fridman: There's a there's a certain sense, which why I initially called it artificial intelligence is like most of us are not working on artificial intelligence. You're you're working on some very specific problem and a set of techniques. At the time, it's machine learning to solve this particular problem. This is not gonna take us to a system that, is anywhere close to the generalizability, of the human mind. Like, the kind of stuff the human mind can do in terms of memory, in terms of cognition, in terms of reasoning, common sense reasoning, this is doesn't seem to take us there.[2:45:58] Dr. Lex Fridman: See, the initial impulse was, can I talk to these folks, do science together, through conversation? And I also thought that there was not enough Now I didn't think there was enough good conversations with world class minds that that I got to meet And not the ones with a book or like, this was just the thing. Oftentimes, you go on this tour when you have a book, but there's a lot of minds that don't write books.[2:46:26] Andrew Huberman: They don't books Drain the conversation too, because then you're talking about this thing, this book.[2:46:31] Dr. Lex Fridman: But there's I've I've noticed that with people who haven't written a book, who are brilliant, We get to talk about ideas in a new way. We both haven't actually when we raise a question, we don't know the answer to it Question is raised, and we try to arrive there. Like, I don't know. I remember asking questions of world class Researchers in, deep learning of why do neural networks work as well as they do, that question It's often loosely asked, but, like, when you have microphones and you have to think through it and you have 30 minutes to an hour to think through it together, I think that's, that's science. I think that's really powerful.[2:47:17] Dr. Lex Fridman: So that was that was the one goal. The other one is, I, again, don't usually talk about this, but there's some sense in which I wanted to have dangerous conversations. Oh, part of the reasons I wanted to wear a suit is, like, I wanted to be fearless. That it The reason I don't usually talk about it is because I feel like I'm not good at conversation. So it looks like it it doesn't match the current skill level, But I wanted to have really, dangerous conversations that I uniquely would be able to do.[2:47:58] Dr. Lex Fridman: Not completely uniquely, but, like, I'm a huge fan of Joe Rogan, and I had to ask myself, what conversations can I do that Joe Rogan can't? For me, I know I bring this up, but for me, that person I thought about at the time was Putin. Like, that's That's why I bring him up. He he's he's, just like with Costello, he's not just a person. He's also an idea to me for what I strive for, Just to have those dangerous conversations.[2:48:27] Dr. Lex Fridman: And the reason I'm uniquely qualified is both the Russian, but also there's the judo and the martial arts. There's a lot of elements That make me have a conversation he hasn't had before. And, and there's a few other people that, I kept in mind, like, Don Knuth is a computer scientist, from Stanford that I thought is one of the most beautiful minds ever. And nobody really talked to him, like, really talked to him. He did a few lectures, which people love, But, really, just have a conversation with him.[2:49:03] Dr. Lex Fridman: There's a few people like that. 1 of them passed away, John Conway, that never got we agreed to talk, but he, died before we did. There's a few people like that that I thought, like, it's such a crime to not hear those folks. And, I have the unique ability to know how to purchase an, microphone on Amazon and plug it into a device that Chord's audio and then publish it, which seems relatively unique. Like, it's that's not easy in the scientific community, people knowing how to plug in a microphone.[2:49:36] Andrew Huberman: No. They can build Faraday cages and 2 photon microscopes and, put the bioengineer, all sorts of things. But, The idea that you could take ideas and export them into a structure or a pseudo structure that people would benefit from seems like, A cosmic achievement to them.[2:49:54] Dr. Lex Fridman: I don't know if it's a fear or just, basically, they haven't tried it, so they haven't they haven't learned the skill level.[2:50:00] Andrew Huberman: But I think they're not trained I mean, we could riff on this for a while, but I think that, but it's important, and maybe we should, which is that it's They're not trained to do it. They're trained to think in specific aims and specific hypotheses, and, and many of them don't care Right? They they don't they they became scientists because, that's where they felt safe, and so why would they leave that, haven of safety?[2:50:25] Dr. Lex Fridman: Well, they also don't necessarily always see the value in it. It's it's we're all together learning. You and I are learning the value of this. I think you're probably you have an exceptionally, successful and amazing podcast that you started just recently. Thanks to your encouragement.[2:50:42] Dr. Lex Fridman: Well but there's there's a raw skill there that that's you're definitely an inspiration, to me in how you do the podcast in the In the level of excellence you reach, but I think you've discovered that that's also an impactful way to do science, that podcast. And I think a lot of Scientists have not yet discovered that that this is, if they apply same kind of rigor as they do to academic publication, or to even conference presentations. And they do that rigor and, effort to, to podcast, whatever that is. That could be a 5 minute podcast, A 2 hour podcast, it could be conversational, or it could be more like lecture like. If they apply that effort, you have the potential to reach, Over time, tens of thousands, hundreds of thousands, millions of people, and that's that's really, really powerful.[2:51:32] Dr. Lex Fridman: But, yeah, for For me, giving a platform to a few of those folks, especially for me personally, So maybe you could speak to what fields you're drawn to, but I thought computer scientists, we're especially bad at this. So there's brilliant computer scientists that I thought, it would be amazing to explore their mind, explore their thinking. And so that I took that almost as an, on as an effort. And at the same time, I had other, guests in mind or people that connect to my own interests. So the the wrestling, wrestling, music, football, both American football and and soccer.[2:52:21] Dr. Lex Fridman: I have a few particular people that I'm really interested in. The Satya brothers, even could be for wrestling, just to talk to them because[2:52:30] Andrew Huberman: Oh, because you can you guys Can communicate[2:52:33] Dr. Lex Fridman: in Russian and in wrestling. Right? As wrestlers and as Russians. And, So that that little it's like an opportunity to explore a mind that, that I'm able to bring to the world. And and and, also, It, I feel like it makes me a better person, just that being that vulnerable and exploring ideas together.[2:52:57] Dr. Lex Fridman: I don't know. Like, good conversation. I don't know how often you have a really good conversation with friends, but, like, podcasts are like that. And, it's it's deeply moving.[2:53:07] Andrew Huberman: It's the best. You know? And and what what you brought through I mean, when I saw you sit down with Penrose, you know, Nobel Prize winning physicist and these other folks, it's not just because he has a Nobel. It's what comes out of his mouth is incredible, and what you were able to, to hold in that conversation was So much better. Light years beyond what he had any other interviewer.[2:53:28] Andrew Huberman: I don't wanna even call you an interviewer because it's really about conversation. Light years beyond what anyone else had been able to, engage with him was, was such a beacon of what's possible. And I I know that I think that's what people are drawn to, and and there's a certain intimacy that, certainly, if 2 people are friends as we are and they know each other, that there's more of that, but There's an intimacy in those kinds of private conversations that are made public. And,[2:53:55] Dr. Lex Fridman: well, the that's the with you, you're probably starting to realize, And Costello is, like, part of it because you're authentic and you're putting yourself out there completely, people are almost Not just consuming the the words you're saying. They also enjoy watching you, Andrew, Struggle with these ideas or try to communicate these ideas. They like the flaws. They like they like a human being. Oh, good.[2:54:23] Dr. Lex Fridman: The like flaws?[2:54:24] Andrew Huberman: Well, that's good because I got plenty of those.[2:54:26] Dr. Lex Fridman: Well, they let the, like, the self critical aspects, like, where you're very careful where where you're very self critical about your flaws. I mean, that in in that same way, it's interesting, I think, for people to watch me talk to Penrose not just because Penrose is communicating ideas, but here's this, like, silly kid trying to explore ideas. Like, they know this kid. The there's a human connection, that is really powerful. Same, I think, with Putin.[2:54:53] Dr. Lex Fridman: Right? Like, it's not just as, a good interview with Putin. It's also here's this kid Struggling to, to talk with one of the most powerful, and some would argue dangerous people in the world. That they love that. The the the authenticity that led up to that.[2:55:11] Dr. Lex Fridman: Like and and in return, I get to connect Everybody I run to in in the street and all those kinds of things, there's a depth of connection there almost within, like, a minute or two that's unlike any other.[2:55:24] Andrew Huberman: Yeah. There's an intimacy that you've formed with with[2:55:26] Dr. Lex Fridman: him. Yeah. We've been on this, like, journey together. I mean, I have the same thing with Joe Rogan before I ever met him. Right?[2:55:32] Dr. Lex Fridman: Like, I was because I was a fan of Joe for so many years, you have there's something there's there's a kind of friendship, as absurd as it might be to say in podcasting and listening to podcasts.[2:55:45] Andrew Huberman: Yeah. Maybe it maybe it fills in a little bit of that or solves a little bit of that loneliness that you're talking about[2:55:51] Dr. Lex Fridman: right now. The robots are here.[2:55:54] Andrew Huberman: I have, just a couple more questions, but, one of them is on behalf of your audience, which is, I'm not gonna ask you the meaning of the hedge Chog. But I just want to know, does it have a name? And you don't have to tell us the name, but just does it have a name, yes or no?[2:56:12] Dr. Lex Fridman: Well, there's a There's a name he likes to be referred to as, and then there's a private name in the privacy of our own company that we call each other. No. I'm not that insane. No. His name is Hedgie.[2:56:27] Dr. Lex Fridman: He's a hedgehog. I don't like stuffed animals, but his story is one of minimalism. So I gave away everything I own, no. Three times in my life. By everything, I mean, almost everything.[2:56:43] Dr. Lex Fridman: Kept jeans and shirt and a laptop. And, recently, it's also been guitar, things like that. But he survived because he was always in the, at least in the first two times, was in the laptop bag, and he just got lucky. And so I just like the perseverance of that. And, I first saw him in the, the reason I got a stuffed animal and I don't have other stuffed animals is, it was in a thrift Door, in this, like, giant pile of stuffed animals, and he jumped out at me because unlike all the rest of them, he has this Intense, mean look about him, that he's just he's upset at life, at the cruelty of life.[2:57:30] Dr. Lex Fridman: And and just especially in the contrast of the other stuffed animals, they have this dumb smile on their face. If you look at most stuffed animals, they have this dumb look on their face. Yeah. They're just happy. It's like Pleasantville.[2:57:40] Andrew Huberman: That's what we say in neuroscience. They have a smooth cortex, not[2:57:43] Dr. Lex Fridman: Yeah.[2:57:43] Andrew Huberman: Not many forms.[2:57:44] Dr. Lex Fridman: Exactly. And this, like, Hedgy, like, saw through all of it. He was like, man from underground. I mean, there's a sense that he saw the darkness of the world and persevered. So, like, and, There's also a famous Russian cartoon, hedgehog in the fog, that I I I grew up with, I connected with.[2:58:04] Dr. Lex Fridman: There's People who, know of that cartoon, you could see it on YouTube. It's like Hedgehog in the fog? Yeah. He it's just as you would Especially from, like, early Soviet cartoons, it's a hedgehog, like, sad, walking through the fog, Exploring, like, loneliness and sadness. It's like but it's beautiful.[2:58:26] Dr. Lex Fridman: It's like a piece of art. People should even if you don't speak Russian, you'll see you'll understand.[2:58:31] Andrew Huberman: Oh, it's in I the moment you said that, I was gonna ask, so it's in Russian, but, of course, it's in[2:58:35] Dr. Lex Fridman: It's in Russian, but it's more there's very little speaking in it. It's almost, there there's an interesting exploration of of, how you make sense of the world when you, see it only vaguely through the fog. So he's trying to understand the world.[2:58:55] Andrew Huberman: Here, we have Mickey Mouse.[2:58:56] Dr. Lex Fridman: Yeah. I know.[2:58:57] Andrew Huberman: We have Bugs Bunny. Yeah. We have all these, you know, crazy What? Animals, and you have the hedgehog in the fog.[2:59:03] Dr. Lex Fridman: So there's a there's a Certain period and this is, again, I don't know what it's attributed to, but it's really powerful, which there's a period in Soviet history, I think probably Seventies and eighties, where, like, especially kids were treated very seriously. Like, they were treated like they're able to deal with the with the weightiness of life, and that that was reflected in the cartoons. And there was a it was allowed to have, like, like, really artistic content. Not like dumb cartoons that are trying to get you to be, like, smile and run around, but, like, create art. Like, stuff that you know how, like, short cartoons or short films can win Oscars?[2:59:54] Andrew Huberman: With respect.[2:59:55] Dr. Lex Fridman: Yeah.[2:59:55] Andrew Huberman: Like, that they have that they have an intelligence, and they honor that intelligence.[2:59:59] Dr. Lex Fridman: Yeah. They're really just adult in a small body. Like, you wanna protect them from the true cruelty of the world Sure. But in terms of their intellectual capacity or, like, philosophical capacity, they're right there with you. And so, The the cartoons reflected that.[3:00:14] Dr. Lex Fridman: The art that they consumed, the education reflected that. So he represents that. I mean, there's a sense of because he survived so long and because I don't like stuffed animals that it's like we've been through all of this Together and it's it's the same, sharing the moments together. It's the friendship. And there's a sense in which, you know, if all the world turns on you and goes to hell, least we got each other.[3:00:40] Dr. Lex Fridman: That, and he doesn't die because he's an inanimate object.[3:00:44] Andrew Huberman: So Until you animate him.[3:00:47] Dr. Lex Fridman: At the to to animate him. And then I probably wouldn't wanna know what he was thinking about this whole time. He's probably really into Taylor Swift or something like that. Sick that I wouldn't even wanna know. Anyway[3:00:58] Andrew Huberman: Well, well, I now feel a connection to Hedgy the Hedgehog that I certainly didn't have before, and I think that the kind of possibility of connection, that is possible between human and and other object and through Through robotics, certainly. There's a saying that I heard when I was a graduate student that I that's just been ringing in my mind Throughout this conversation in such a, I think, appropriate way, which is that, Lex, you are in a minority of 1. You are Truly, extraordinary in your ability to encapsulate so many aspects of science, engineering, Public communication about so many topics, martial arts, and the emotional depth that you bring to it, and just the purpose Fullness, and I think if it's not clear to people, it absolutely should be stated. But I think it's abundantly clear that Just the amount of time and thinking that you put into things is, it it is the ultimate mark of respect. So I'm just extraordinarily grateful for your friendship and for this conversation.[3:02:09] Dr. Lex Fridman: I'm, proud to be your friend, and I just wish you showed me the same kind of respect by wearing a To make your father proud, maybe next time.[3:02:17] Andrew Huberman: Next time indeed. Thanks so much, my friend.[3:02:20] Dr. Lex Fridman: Thank you. Thank you, Andrew.[3:02:22] Andrew Huberman: Thank you for joining me for my discussion with doctor Lex Fridman. If you're enjoying this podcast and learning from it, please consider subscribing on YouTube. As well, you can subscribe to us on Spotify or Apple. Please leave any questions and comments and suggestions that you have for future podcast episodes and guests In the comment section on YouTube. At Apple, you can also leave us up to a 5 star review.[3:02:46] Andrew Huberman: If you'd like to support this podcast, we have a Patreon. That's patreon.com/andrewhuberman. And there, you can support us at any level that you like. Also, Please check out our sponsors mentioned at the beginning of the podcast episode. That's the best way to support this podcast.[3:03:03] Andrew Huberman: Links to our sponsors can be found in the show notes. And finally, thank you for your interest in science.